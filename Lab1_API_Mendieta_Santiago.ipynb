{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wgigj_IaZB6"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 30%;\">\n",
    "<img src=\"https://www.utpl.edu.ec/sites/default/files/archivos/marca%20UTPL%202018-02.png\", align=\"left\" width=\"280\" height=\"120\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 70%;\">\n",
    "<p style=\"margin: 0; padding-top: 32px; text-align:right; color:#003366; font-size:16px\"><u>Análisis de datos y visualización</u></p>\n",
    "<p style=\"margin: 0; text-align:right; color:#999999; font-size:17px\">Maestría en Inteligencia Artificial Aplicada</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Laboratorio 1: Extracción de datos mediante APIs\n",
    "\n",
    "La actividad práctico experimental tiene como objetivo validar su habilidad para usar APIs públicas para la extracción de datos.\n",
    "\n",
    "Desarrolle los ejercicios relacionados con la extracción y procesamiento de datos planteados en el notebook.\n",
    "\n",
    "Por cada ejercicio revise las indicaciones proporcionadas, para conseguir así el resultado que se espera.\n",
    "\n",
    "\n",
    "<b>Entregable de la actividad:</b>\n",
    "\n",
    "En la tarea habilitada, suba el notebook con la solución (en formato html o pdf). Antes de subir la solución verifique que consten todas las salidas que se esperan de cada ejercicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x97WwfMzdd95"
   },
   "source": [
    "## Paso 1: Configuración de acceso a API de Kaggle\n",
    "\n",
    "<b>Objetivo:</b> Conseguir un API token para comenzar a extraer los datos desde Kaggle.\n",
    "\n",
    "<b>Pasos:</b>\n",
    "\n",
    "1. Crear cuenta en Kaggle: https://www.kaggle.com/account/login\n",
    "2. Revisar la documentación de la API: https://www.kaggle.com/docs/api y seguir los pasos que constan en la sección <b>Authentication</b> para conseguir un API token. Según la documentación:\n",
    "\n",
    "&emsp;&emsp;&emsp;- <i>In order to use the Kaggle’s public API, you must first authenticate using an API token. Go to the 'Account' tab of your user profile and select 'Create New Token'. This will trigger the download of kaggle.json, a file containing your API credentials.</i>\n",
    "\n",
    "&emsp;&emsp;&emsp;Como resultado de esta acción guardar el archivo <b>kaggle.json</b>.\n",
    "\n",
    "4. Configurar credenciales de acceso: Dependiendo del entorno en el que trabaje hay dos opciones para hacer la configuración:\n",
    "\n",
    "&emsp;&emsp;4.1. Si es un entorno local, la documentación indica que hay que copiar el archivo kaggle.json en un directorio específico, según la siguiente instrucción.\n",
    "\n",
    "- <i>If you are using the Kaggle CLI tool, the tool will look for this token at ~/.kaggle/kaggle.json on Linux, OSX, and other UNIX-based operating systems, and at C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json on Windows. If the token is not there, an error will be raised. Hence, once you’ve downloaded the token, you should move it from your Downloads folder to this folder.</i>\n",
    "\n",
    "\n",
    "&emsp;&emsp;4.2. Si es en Google Colab: ejecutar los siguientes pasos cada vez que ingrese a Google Colab.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sh01J5JNaZB-"
   },
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from PIL import Image\n",
    "from IPython.core import display as ICD\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTnSnTnQaZB_"
   },
   "source": [
    "## Paso 2: Carga de palabras clave para realizar la búsqueda\n",
    "\n",
    "Objetivo: Cargar archivo de palabras clave y crear lista que sea procesable por la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "ULqyuCfsaZB_",
    "outputId": "f228475b-4be7-472c-b4b1-13b1a3f1196b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras clave:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binary classication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>missing values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword\n",
       "0    linear regression\n",
       "1  binary classication\n",
       "2        visualization\n",
       "3              poverty\n",
       "4             COVID 19\n",
       "5                  EDA\n",
       "6       missing values\n",
       "7             outliers"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar lista de palabras clave:\n",
    "kwDF = pd.read_csv('keywords.csv', header=None, names=['keyword']) # archivo sin encabezado\n",
    "\n",
    "print(\"Cantidad de palabras clave: \", kwDF.shape[0])\n",
    "\n",
    "kwDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK5c-IkXaZCB"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio: (1 pto) </b>\n",
    "\n",
    "<b>Objetivo:</b> Convertir los términos de varias palabras (separadas con espacio ' '), a términos cuyas palabras estén separadas con el signo '-'\n",
    "\n",
    "<b>Requisito:</b> La lista deberá llamarse  <i>kw</i>.\n",
    "\n",
    "<b>Salida esperada:</b> Objeto tipo lista que contenga los términos preprocesados.\n",
    "\n",
    "Por ejemplo, para el primer caso, en lugar de \"linear regression\" se debe generar el término \"linear_regression\"\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYKwU3QIaZCC",
    "outputId": "99d8abc5-83c0-41ce-cfee-3d9d6bbfc775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear_regression', 'binary_classication', 'visualization', 'poverty', 'COVID_19', 'EDA', 'missing_values', 'outliers']\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "#####################\n",
    "\n",
    "nfilas=len(kwDF)        #Numero de filas del dataframe con los Keywords.\n",
    "rango=range(0,nfilas)   #Rango desde cero hasta el numero de filas (0 a 8).\n",
    "kw=[]                   #Lista vacia para almacenar los palabras keywords con guiones.\n",
    "\n",
    "for fila in rango:                                       #Ciclo for para recorrer todas las filas del dataframe kwDF.\n",
    "    palabra=kwDF.loc[fila][\"keyword\"].replace(' ','_')   #Se reemplaza el espacio de cada keyword por un signo '_'.\n",
    "    kw.append(palabra)                                   #Se añaden los keywords a la lista kw.\n",
    "print(kw)                                                #Se imprime la lista kw para verificar los cambios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4JhWLx4aZCC"
   },
   "source": [
    "## Paso 2: Extracción de datos mediante API\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vb36fIxaZCD"
   },
   "source": [
    "### Paso 2.1. Extracción de datos desde Kaggle\n",
    "\n",
    "Consultar Documentación de la API: https://github.com/Kaggle/kaggle-api\n",
    "\n",
    "Luego de la revisión de la documentación, intentar comprender el procedimiento para obtener datasets y notebooks, con el objetivo de obtener las salidas que se esperan de cada ejercicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHH9mQ2IaZCF"
   },
   "source": [
    "### Preparar el request (importar libraries y definir parámetros generales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BGFsgdhLaZCF"
   },
   "outputs": [],
   "source": [
    "import requests, json, time, random\n",
    "# importar libreria kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0pHufYNraZCG"
   },
   "outputs": [],
   "source": [
    "# Llamar a la api key de kaggle instalada en el entorno seleccionado.\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYTUuiDRaZCG"
   },
   "source": [
    "Aunque la documentación de la API explica el proceso de consumo de datos, a continuación se presenta un ejemplo de extracción de metadatos de dataset. Observe los metadatos que devuelve la API y pruebe cómo obtendría los metadatos de notebooks.\n",
    "\n",
    "\n",
    "A partir del ejemplo planteado, desarrolle los ejercicios que continuan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBsjskuSaZCG",
    "outputId": "5355f1ba-f977-4a2c-a3d6-40fa6c3bfc87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,size,lastUpdated,downloadCount,voteCount,usabilityRating',\n",
       " 'aml0ali2000/linear-regression,Linear_regression,1KB,2023-12-04 14:34:14,7,2,0.3529412',\n",
       " 'kasiviswanath00/linear-regression,linear_regression,378B,2022-05-25 12:08:15,15,2,0.1764706',\n",
       " 'drakedyban/mediumlinear-regression,Medium-Linear_Regression,5KB,2021-02-28 22:37:25,19,1,0.4375',\n",
       " 'sangitamule/linear-regressionproject,/Linear_Regression-Project,40KB,2022-02-03 06:41:39,14,2,0.29411766',\n",
       " 'krishnamohanmaurya/linear-regression,Linear_Regression,5KB,2023-02-27 14:38:50,7,2,0.1764706']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso de la API:\n",
    "\n",
    "# Extracción de datasets:\n",
    "tema = kw[0]  # toma el primer término o palabra que se cargó desde el csv\n",
    "page = 1  # obtener los datos de la primera página, se puede cambiar iterativamente este valor para recuperar más resultados\n",
    "\n",
    "#Llamada para obtener metadatos de datasets de un tema en particular y de una página específica.\n",
    "lista = !kaggle datasets list -s $tema --csv -p $page  \n",
    "results=[l for l in lista if len(l)]       #Se filtran los resultados para que no se incluyan en la lista elementos vacios.\n",
    "results[:6]                                # Presentar los 5 primeros resutados en forma de lista, incluyendo el resultado para las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ref                       title  size  \\\n",
       "1         aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2     kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3    drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4  sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5  krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "\n",
       "           lastUpdated downloadCount voteCount usabilityRating  \n",
       "1  2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2  2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3  2021-02-28 22:37:25            19         1          0.4375  \n",
       "4  2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5  2023-02-27 14:38:50             7         2       0.1764706  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos adicionales del ejemplo para mostrar los 5 primeros resultados en un DataFrame\n",
    "results2=[]             #Nueva lista vacía\n",
    "d=len(results)          #Numero de elementos de la lista de resultados de datasets\n",
    "r=range(0,d)            #Rango para la iteracion\n",
    "for i in r:                                #Ciclo repetitivo para recorrer toda la lista results\n",
    "    results_split=results[i].split(',')    #Se separan los elementos de cada posicion de la lista results\n",
    "    results2.append(results_split)         #Se añaden cada lista de elementos separados en la lista results2\n",
    "results_DF=pd.DataFrame(results2, columns=results2[0])     #Se transforma en dataframe la lista results2 (lista de listas)\n",
    "results_DF[1:6]                            #Se muestran los primeros 5 resultados, sin contar el resultado para las columnas                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_JA8KqXaZCH"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 2 (1.75 ptos): Obtención de metadatos de datasets.</b>\n",
    "\n",
    "<b>Objetivo:</b> Mediante un proceso repetitivo, recuperar los <b>datasets</b> que estén relacionados con las palabras clave contenidas en la lista de keywords previamente creada (<i>kw</i>).\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer toda la lista de palabras clave para obtener todos los datasets que consten en las primeras 3 páginas (por cada palabra clave).\n",
    "- Acumular los resultados en una lista que se denomine <i> datasets </i>\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros datasets recuperados.\n",
    "\n",
    "En el ejemplo, proporcionado arriba, puede ver una muestra de los resultados esperados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CknVrp43aZCH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,size,lastUpdated,downloadCount,voteCount,usabilityRating',\n",
       " 'aml0ali2000/linear-regression,Linear_regression,1KB,2023-12-04 14:34:14,7,2,0.3529412',\n",
       " 'kasiviswanath00/linear-regression,linear_regression,378B,2022-05-25 12:08:15,15,2,0.1764706',\n",
       " 'drakedyban/mediumlinear-regression,Medium-Linear_Regression,5KB,2021-02-28 22:37:25,19,1,0.4375',\n",
       " 'sangitamule/linear-regressionproject,/Linear_Regression-Project,40KB,2022-02-03 06:41:39,14,2,0.29411766',\n",
       " 'krishnamohanmaurya/linear-regression,Linear_Regression,5KB,2023-02-27 14:38:50,7,2,0.1764706',\n",
       " 'iflahgulzar/linear-regression,linear_regression,8KB,2023-02-26 16:36:10,9,1,0.1764706',\n",
       " 'viveckrajasekar/linear-regression,Linear_Regression,13KB,2019-06-28 14:24:45,61,1,0.11764706',\n",
       " 'pankajsinghardh/linear-regression,linear_regression,213B,2023-08-27 05:40:10,6,0,0.3125',\n",
       " 'nurmannaz/linear-regression,linear_regression,220B,2022-03-01 21:17:06,14,0,0.1764706']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "# Extracción de datasets:\n",
    "datasets=[]                     #Lista vacía para guardar todos los datasets\n",
    "rango2=range(1,4)               #Rango para el numero de paginas: 1,2 y 3.\n",
    "for fila in rango:                                 #Ciclo repetitivo para recorrer todas las keywords de la lista kw\n",
    "    for pagina in rango2:                          #Ciclo repetitivo para recorrer las paginas\n",
    "        tema = kw[fila]                            #Se toma cada keyword y se le asigna a la variable tema\n",
    "        page = pagina                              #Cada pagina se asigna a la variable page      \n",
    "        #Llamada para obtener metadatos de datasets de un tema y de una página específica. Los resultados se guardan en una lista.\n",
    "        lista = !kaggle datasets list -s $tema --csv -p $page \n",
    "        results=[l for l in lista if len(l) and l!='No datasets found']  #Se filtran los resultados para que no se incluyan elementos vacios.      \n",
    "        datasets.extend(results)                   #Los resultados de cada iteración se acumulan en la lista llamada datasets\n",
    "datasets[:10]                                      #Se presentan los primeros 10 resutados de la lista datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iflahgulzar/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2023-02-26 16:36:10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viveckrajasekar/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2019-06-28 14:24:45</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nurmannaz/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>220B</td>\n",
       "      <td>2022-03-01 21:17:06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epsitabose/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2022-02-09 11:47:13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ref                       title  size  \\\n",
       "1          aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2      kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3     drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4   sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5   krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "6          iflahgulzar/linear-regression           linear_regression   8KB   \n",
       "7      viveckrajasekar/linear-regression           Linear_Regression  13KB   \n",
       "8      pankajsinghardh/linear-regression           linear_regression  213B   \n",
       "9            nurmannaz/linear-regression           linear_regression  220B   \n",
       "10          epsitabose/linear-regression           linear_regression   2MB   \n",
       "\n",
       "            lastUpdated downloadCount voteCount usabilityRating  \n",
       "1   2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2   2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3   2021-02-28 22:37:25            19         1          0.4375  \n",
       "4   2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5   2023-02-27 14:38:50             7         2       0.1764706  \n",
       "6   2023-02-26 16:36:10             9         1       0.1764706  \n",
       "7   2019-06-28 14:24:45            61         1      0.11764706  \n",
       "8   2023-08-27 05:40:10             6         0          0.3125  \n",
       "9   2022-03-01 21:17:06            14         0       0.1764706  \n",
       "10  2022-02-09 11:47:13             6         1             0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos para mostrar los 10 primeros resultados de la lista datasets en un DataFrame\n",
    "datasets2=[]            #Nueva lista vacía\n",
    "d=len(datasets)       #Numero de elementos de la lista datasets\n",
    "r=range(0,d)         #Rango para la iteracion\n",
    "for i in r:                                  #Ciclo repetitivo para recorrer toda la lista datasets\n",
    "    datasets_split=datasets[i].split(',',6)  #Se separan los elementos de cada posicion de la lista datasets\n",
    "    datasets2.append(datasets_split)         #Se añade cada lista de elementos separados en la lista datasets2\n",
    "datasets_DF=pd.DataFrame(datasets2, columns=datasets2[0])  #Se transforma en dataframe la lista datasets2 (lista de listas)\n",
    "datasets_DF[1:11]                            #Se muestran los primeros 10 resultados de los datasets, sin incluir los resultados para las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>mryanm/luflow-network-intrusion-detection-data...</td>\n",
       "      <td>LUFlow Network Intrusion Detection Data Set</td>\n",
       "      <td>5GB</td>\n",
       "      <td>2024-04-27 08:57:48</td>\n",
       "      <td>2514</td>\n",
       "      <td>70</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>swatikhedekar/eda-on-zomato-dataset</td>\n",
       "      <td>EDA on Zomato dataset</td>\n",
       "      <td>440KB</td>\n",
       "      <td>2022-06-05 11:20:03</td>\n",
       "      <td>582</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kimjihoo/coronavirusdataset</td>\n",
       "      <td>[NeurIPS 2020] Data Science for COVID-19 (DS4C)</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2020-07-13 14:07:31</td>\n",
       "      <td>139620</td>\n",
       "      <td>1597</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mitchellreynolds/multidimensional-poverty-meas...</td>\n",
       "      <td>Multidimensional Poverty Measures</td>\n",
       "      <td>49KB</td>\n",
       "      <td>2018-03-28 18:24:10</td>\n",
       "      <td>706</td>\n",
       "      <td>16</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>utkarshtomar736/odi-mens-cricket-match-data-20...</td>\n",
       "      <td>ODI Men's Cricket Match Data (2002-2023)</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2023-09-25 15:31:05</td>\n",
       "      <td>1620</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>helddata/yellow-taxi-trip-data-2017</td>\n",
       "      <td>Yellow Taxi Trip Data 2017</td>\n",
       "      <td>675KB</td>\n",
       "      <td>2023-12-09 18:13:20</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>moro146/supermarket-eda</td>\n",
       "      <td>supermarket EDA</td>\n",
       "      <td>480KB</td>\n",
       "      <td>2023-01-29 21:07:04</td>\n",
       "      <td>279</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rohan0301/unsupervised-learning-on-country-data</td>\n",
       "      <td>Unsupervised Learning on Country Data</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2020-06-17 07:45:45</td>\n",
       "      <td>22938</td>\n",
       "      <td>199</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>rohitsahoo/sales-forecasting</td>\n",
       "      <td>Superstore Sales Dataset</td>\n",
       "      <td>480KB</td>\n",
       "      <td>2020-09-11 15:40:14</td>\n",
       "      <td>63068</td>\n",
       "      <td>459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>anshtanwar/monthly-food-price-estimates</td>\n",
       "      <td>Global Food Price Inflation</td>\n",
       "      <td>254KB</td>\n",
       "      <td>2023-10-21 15:33:25</td>\n",
       "      <td>10951</td>\n",
       "      <td>162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "276  mryanm/luflow-network-intrusion-detection-data...   \n",
       "229                swatikhedekar/eda-on-zomato-dataset   \n",
       "28                         kimjihoo/coronavirusdataset   \n",
       "83   mitchellreynolds/multidimensional-poverty-meas...   \n",
       "35   utkarshtomar736/odi-mens-cricket-match-data-20...   \n",
       "242                helddata/yellow-taxi-trip-data-2017   \n",
       "191                            moro146/supermarket-eda   \n",
       "92     rohan0301/unsupervised-learning-on-country-data   \n",
       "200                       rohitsahoo/sales-forecasting   \n",
       "111            anshtanwar/monthly-food-price-estimates   \n",
       "\n",
       "                                               title   size  \\\n",
       "276      LUFlow Network Intrusion Detection Data Set    5GB   \n",
       "229                            EDA on Zomato dataset  440KB   \n",
       "28   [NeurIPS 2020] Data Science for COVID-19 (DS4C)    7MB   \n",
       "83                 Multidimensional Poverty Measures   49KB   \n",
       "35          ODI Men's Cricket Match Data (2002-2023)    7MB   \n",
       "242                       Yellow Taxi Trip Data 2017  675KB   \n",
       "191                                  supermarket EDA  480KB   \n",
       "92             Unsupervised Learning on Country Data    5KB   \n",
       "200                         Superstore Sales Dataset  480KB   \n",
       "111                      Global Food Price Inflation  254KB   \n",
       "\n",
       "             lastUpdated downloadCount voteCount usabilityRating  \n",
       "276  2024-04-27 08:57:48          2514        70          0.8125  \n",
       "229  2022-06-05 11:20:03           582         5       0.7058824  \n",
       "28   2020-07-13 14:07:31        139620      1597             1.0  \n",
       "83   2018-03-28 18:24:10           706        16      0.85294116  \n",
       "35   2023-09-25 15:31:05          1620        35             1.0  \n",
       "242  2023-12-09 18:13:20            62         8             1.0  \n",
       "191  2023-01-29 21:07:04           279        32       0.4117647  \n",
       "92   2020-06-17 07:45:45         22938       199             1.0  \n",
       "200  2020-09-11 15:40:14         63068       459             1.0  \n",
       "111  2023-10-21 15:33:25         10951       162             1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_DF.sample(10)                       #Se muestran 10 resultados al azar de los datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvSrdH36aZCI"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 3 (1.75 puntos): Limpieza de metadatos de datasets.</b>\n",
    "\n",
    "<b>Objetivo:</b> Limpiar los metadatos de datasets de tal manera que no hayan elementos duplicados, ni hayan datos con valores inesperados.\n",
    "\n",
    "<b>Contexto:</b> Algunos datasets pueden repetirse en diferentes llamada, esto puede ocurrir cuando un dataset está asociado a varias palabras clave que constan en el archivo de keywords. Por ejemplo, si un dataset tiene dos palabras clave como: linear regression y COVID-19, entonces, va a salir en ambos resultados.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer la lista de resultados <i> datasets </i> y dejar solo resultados únicos de datasets.\n",
    "- Explorar los resultados obtenidos para verificar que los datos no contienen caracteres o elementos extraños.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros datasets únicos que han sido procesados.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CXRRB26caZCI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con valores nulos por columnas:\n",
      "ref                0\n",
      "title              3\n",
      "size               3\n",
      "lastUpdated        3\n",
      "downloadCount      3\n",
      "voteCount          3\n",
      "usabilityRating    3\n",
      "dtype: int64\n",
      "\n",
      "DataFrame con valores nulos por filas:\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "      ..\n",
      "283    0\n",
      "284    0\n",
      "285    0\n",
      "286    0\n",
      "287    6\n",
      "Length: 287, dtype: int64\n",
      "\n",
      "DataFrame solamente con las filas nulas:\n",
      "48     6\n",
      "114    6\n",
      "287    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "#Para la solucion se decide trabajar con los resultados obtenidos de los datasets en formato DataFrame\n",
    "\n",
    "#a.) Eliminación de los resultados duplicados del Dataframe\n",
    "datasets_DF_p=datasets_DF.drop_duplicates()                      #Se utiliza drop_duplicates() para eliminar las filas duplicadas\n",
    "datasets_DF_pp=datasets_DF_p.drop([0],axis=0)                    #Se elimina la primera fila que corresponde con los nombres de las columnas.\n",
    "datasets_DF_pp.index=range(1,len(datasets_DF_pp)+1)              #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_inicial=len(datasets_DF)                               #Se utiliza len para medir el tamaño del dataset sin procesar\n",
    "dimension_sin_duplicados=len(datasets_DF_pp)                     #Se utiliza len para medir el tamaño del dataset preprocesado\n",
    "cantidad_duplicados=dimension_inicial-dimension_sin_duplicados   #Se calcula la cantidad de elementos duplicados\n",
    "\n",
    "#b.) Verificar si hay valores inesperados\n",
    "valores_null_columnas=datasets_DF_pp.isnull().sum()              #Se guarda en un DataFrame el numero de valores nulos por columnas\n",
    "valores_null_filas=(datasets_DF_pp.isnull().sum(axis=1))         #Se guarda en un DataFrame el numero de valores nulos por filas\n",
    "\n",
    "filas_nulas=[]                                                   #Lista vacia para almacenar las filas nulas                   \n",
    "for j in range(1,len(valores_null_filas)+1):                     #Ciclo repetitivo para recorrer el DataFrame con el numero de valores nulos por filas\n",
    "    if valores_null_filas[j]!=0:                                 #Cuando el valor de la fila es distinto de cero se añade en la lista \n",
    "        filas_nulas.append(j)\n",
    "valores_null_filas_filtradas=valores_null_filas[filas_nulas]     #Dataframe solamente con las filas nulas\n",
    "\n",
    "print(\"DataFrame con valores nulos por columnas:\")               #Se imprime el DataFrame con el numero de valores nulos por columnas\n",
    "print(valores_null_columnas)\n",
    "print(\"\\nDataFrame con valores nulos por filas:\")                #Se imprime el DataFrame con el numero de valores nulos por filas\n",
    "print(valores_null_filas)\n",
    "print(\"\\nDataFrame solamente con las filas nulas:\")              #Se imprimen el Dataframe anterior solamente con las filas nulas\n",
    "print(valores_null_filas_filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De  acuerdo al analisis anterior existen 3 filas con valores nulos. Las cuales tienen vacias todas sus columnas a excepcion de la primera\n",
    "#Se decide eliminar estas filas \n",
    "\n",
    "datasets_DF_prep=datasets_DF_pp.drop(filas_nulas,axis=0)         #Se eliminan las filas con valores nulos\n",
    "datasets_DF_prep.index=range(1,len(datasets_DF_prep)+1)          #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_final=len(datasets_DF_prep)                            #Se utiliza len para medir el tamaño del dataset preprocesado final\n",
    "filas_eliminadas_vacias=len(filas_nulas)                         #Se utiliza len para medir el tamaño de filas eliminadas\n",
    "cantidad_filas_eliminadas=dimension_inicial-dimension_final      #Se calcula la cantidad de elementos eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension inicial del Dataframe: 307\n",
      "Dimension del Dataframe sin elementos duplicados: 287\n",
      "Cantidad de filas duplicadas: 20\n",
      "Dimension del DataFrame con datos únicos preprocesados: 284\n",
      "Cantidad de filas eliminadas vacias: 3\n",
      "Cantidad total de filas eliminadas: 23\n",
      "\n",
      "Dataframe con datos únicos preprocesados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iflahgulzar/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2023-02-26 16:36:10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viveckrajasekar/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2019-06-28 14:24:45</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nurmannaz/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>220B</td>\n",
       "      <td>2022-03-01 21:17:06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epsitabose/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2022-02-09 11:47:13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ref                       title  size  \\\n",
       "1          aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2      kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3     drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4   sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5   krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "6          iflahgulzar/linear-regression           linear_regression   8KB   \n",
       "7      viveckrajasekar/linear-regression           Linear_Regression  13KB   \n",
       "8      pankajsinghardh/linear-regression           linear_regression  213B   \n",
       "9            nurmannaz/linear-regression           linear_regression  220B   \n",
       "10          epsitabose/linear-regression           linear_regression   2MB   \n",
       "\n",
       "            lastUpdated downloadCount voteCount usabilityRating  \n",
       "1   2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2   2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3   2021-02-28 22:37:25            19         1          0.4375  \n",
       "4   2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5   2023-02-27 14:38:50             7         2       0.1764706  \n",
       "6   2023-02-26 16:36:10             9         1       0.1764706  \n",
       "7   2019-06-28 14:24:45            61         1      0.11764706  \n",
       "8   2023-08-27 05:40:10             6         0          0.3125  \n",
       "9   2022-03-01 21:17:06            14         0       0.1764706  \n",
       "10  2022-02-09 11:47:13             6         1             0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c.) Impresion de resultados\n",
    "print(\"Dimension inicial del Dataframe:\",dimension_inicial)      #Se imprime el tamaño del dataset sin procesar\n",
    "print(\"Dimension del Dataframe sin elementos duplicados:\",dimension_sin_duplicados)   #Se imprime el tamaño del dataset preprocesado\n",
    "print(\"Cantidad de filas duplicadas:\",cantidad_duplicados)   #Se imprime la cantidad de elementos duplicados\n",
    "print(\"Dimension del DataFrame con datos únicos preprocesados:\",dimension_final)      #Se imprime la cantidad de elementos del DataFrame preprocesado\n",
    "print(\"Cantidad de filas eliminadas vacias:\",filas_eliminadas_vacias)   #Se imprime la cantidad de filas eliminadas vacias\n",
    "print(\"Cantidad total de filas eliminadas:\",cantidad_filas_eliminadas)  #Se imprime la cantidad total de filas_eliminadas\n",
    "print(\"\\nDataframe con datos únicos preprocesados:\")                           \n",
    "datasets_DF_prep[:10]                                            #Se imprimen los 10 primeros resultados del DataFrame preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ramjasmaurya/mineral-ores-around-the-world</td>\n",
       "      <td>Mineral ores around the world</td>\n",
       "      <td>9MB</td>\n",
       "      <td>2022-04-27 04:59:35</td>\n",
       "      <td>2033</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>broach/button-tone-sz</td>\n",
       "      <td>EEG data from basic sensory task in Schizophrenia</td>\n",
       "      <td>8GB</td>\n",
       "      <td>2019-01-31 18:26:06</td>\n",
       "      <td>7173</td>\n",
       "      <td>215</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>vivmankar/physics-vs-chemistry-vs-biology</td>\n",
       "      <td>Physics vs Chemistry vs Biology</td>\n",
       "      <td>950KB</td>\n",
       "      <td>2021-11-01 08:15:16</td>\n",
       "      <td>2229</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>brandonconrady/living-wage-top-100-cities</td>\n",
       "      <td>Living Wage - Top 100 Cities</td>\n",
       "      <td>6KB</td>\n",
       "      <td>2021-12-18 03:42:47</td>\n",
       "      <td>1496</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>duyquhu/covid-19</td>\n",
       "      <td>Covid_19</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2022-05-03 11:11:52</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>senapatirajesh/corona-virus-vaccination-jan2023</td>\n",
       "      <td>Latest worldwide Covid_19 vaccination data</td>\n",
       "      <td>18KB</td>\n",
       "      <td>2023-01-14 08:40:17</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>vijaykumar1799/face-mask-detection</td>\n",
       "      <td>Face Mask Detection</td>\n",
       "      <td>222MB</td>\n",
       "      <td>2021-05-19 15:24:14</td>\n",
       "      <td>6079</td>\n",
       "      <td>74</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>iamsouravbanerjee/human-development-index-dataset</td>\n",
       "      <td>Human Development World Index</td>\n",
       "      <td>626KB</td>\n",
       "      <td>2024-03-01 09:30:30</td>\n",
       "      <td>2743</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>l10677832/outliers</td>\n",
       "      <td>outliers</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2023-11-13 12:11:04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "219         ramjasmaurya/mineral-ores-around-the-world   \n",
       "8                    pankajsinghardh/linear-regression   \n",
       "236                              broach/button-tone-sz   \n",
       "217          vivmankar/physics-vs-chemistry-vs-biology   \n",
       "104          brandonconrady/living-wage-top-100-cities   \n",
       "138                                   duyquhu/covid-19   \n",
       "131    senapatirajesh/corona-virus-vaccination-jan2023   \n",
       "249                 vijaykumar1799/face-mask-detection   \n",
       "110  iamsouravbanerjee/human-development-index-dataset   \n",
       "280                                 l10677832/outliers   \n",
       "\n",
       "                                                 title   size  \\\n",
       "219                      Mineral ores around the world    9MB   \n",
       "8                                    linear_regression   213B   \n",
       "236  EEG data from basic sensory task in Schizophrenia    8GB   \n",
       "217                    Physics vs Chemistry vs Biology  950KB   \n",
       "104                       Living Wage - Top 100 Cities    6KB   \n",
       "138                                           Covid_19   13KB   \n",
       "131         Latest worldwide Covid_19 vaccination data   18KB   \n",
       "249                                Face Mask Detection  222MB   \n",
       "110                      Human Development World Index  626KB   \n",
       "280                                           outliers    2MB   \n",
       "\n",
       "             lastUpdated downloadCount voteCount usabilityRating  \n",
       "219  2022-04-27 04:59:35          2033        76             1.0  \n",
       "8    2023-08-27 05:40:10             6         0          0.3125  \n",
       "236  2019-01-31 18:26:06          7173       215      0.88235295  \n",
       "217  2021-11-01 08:15:16          2229        40       0.9705882  \n",
       "104  2021-12-18 03:42:47          1496        31             1.0  \n",
       "138  2022-05-03 11:11:52            18         1       0.1764706  \n",
       "131  2023-01-14 08:40:17            75         5       0.7647059  \n",
       "249  2021-05-19 15:24:14          6079        74           0.875  \n",
       "110  2024-03-01 09:30:30          2743       107             1.0  \n",
       "280  2023-11-13 12:11:04             1         1            0.25  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_DF_prep.sample(10)                                      #Se muestran 10 resultados al azar del DataFrame preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6ufgdIiaZCK"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 4 (1.75 puntos): Obtención de metadatos de notebooks.</b>\n",
    "\n",
    "<b>Objetivo:</b> Mediante un proceso repetitivo, recuperar los <b>notebooks</b> que estén relacionados con las palabras clave contenidas en la lista de keywords previamente creada (<i>kw</i>). Este ejercicio es similar anterior, pero, la idea es centrarse en los notebooks.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer toda la lista de palabras clave para obtener todos los notebooks que consten en las primeras 3 páginas (por cada palabra clave).\n",
    "- Acumular los resultados en una lista que se denomine <i> notebooks </i>\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros notebooks recuperados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "J268BLRgaZCK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,author,lastRunTime,totalVotes',\n",
       " 'hakmatkhan/linear-regression,Linear_regression,Hakmat khan,2023-01-05 15:30:05,2',\n",
       " 'sanket82/linear-regression,Linear_Regression,Sanket Adamapure,2022-01-30 17:04:53,2',\n",
       " 'nkitgupta/feature-engineering-and-feature-selection,Feature Engineering and Feature Selection,Ankit Gupta,2022-04-28 13:34:32,172',\n",
       " 'baljeeta/linear-regression-medical-insurance,Linear_regression(Medical_Insurance),Baljeeta,2024-03-22 10:51:07,6',\n",
       " 'meltemsprtl/linear-regression,linear_regression,Meltem SUPURTULU,2022-02-09 07:51:36,3',\n",
       " 'abdul3344/linear-regression,Linear_Regression,Abdul3344,2022-11-07 17:17:21,3',\n",
       " 'mustiztemiz/linear-regression-house-rice-prediction,Linear_Regression _House_rice_prediction,mustafa öztemiz,2021-11-12 17:16:49,5',\n",
       " 'rashmiek99/head-size-vs-brain-weight,Head Size Vs Brain Weight,Rashmi,2019-08-01 01:03:35,24',\n",
       " 'aiyoweidtt/linear-regression-decision-tree-random-forest,Linear_Regression/Decision_Tree/Random_Forest,Aiyowei,2019-08-22 08:50:50,3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "# Extracción de notebooks:\n",
    "notebooks=[]                    #Lista vacía para guardar todos los notebooks\n",
    "num_filas=len(kw)               #Numero de filas de kw\n",
    "rango=range(0,num_filas)        #Rango para el numero de filas de lista kw\n",
    "rango2=range(1,4)               #Rango para el numero de paginas: 1,2 y 3.\n",
    "for fila in rango:                                 #Ciclo repetitivo para recorrer todas las keywords de la lista kw\n",
    "    for pagina in rango2:                          #Ciclo repetitivo para recorrer las paginas\n",
    "        tema = kw[fila]                            #Se toma cada keyword y se le asigna a la variable tema\n",
    "        page = pagina                              #Cada pagina se asigna a la variable page      \n",
    "        #Llamada para obtener metadatos de notebooks de un tema y de una página específica. Los resultados se guardan en una lista.\n",
    "        lista = !kaggle kernels list -s $tema --csv -p $page \n",
    "        results=[l for l in lista if len(l) and l!='Not found']   #Se filtran los resultados para que no se incluyan elementos vacios.      \n",
    "        notebooks.extend(results)                  #Los resultados de cada iteración se acumulan en la lista llamada notebooks\n",
    "a=0                                                #Se declara la variable 'a' para el bucle while\n",
    "while a==0 or a==1:                                #Bucle while para que se ejecute dos veces\n",
    "    notebooks.remove(notebooks[0])                 #Se elimina el primer y segundo termino de la lista obtenida, dado que en la llamada...\n",
    "    a+=1                                           #...corresponden con los titulos de las columnas (ref,title,author,lastRunTime,totalVotes)\n",
    "notebooks[:10]                                     #Se presentan los primeros 10 resutados de la lista notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hakmatkhan/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>Hakmat khan</td>\n",
       "      <td>2023-01-05 15:30:05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanket82/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Sanket Adamapure</td>\n",
       "      <td>2022-01-30 17:04:53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nkitgupta/feature-engineering-and-feature-sele...</td>\n",
       "      <td>Feature Engineering and Feature Selection</td>\n",
       "      <td>Ankit Gupta</td>\n",
       "      <td>2022-04-28 13:34:32</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baljeeta/linear-regression-medical-insurance</td>\n",
       "      <td>Linear_regression(Medical_Insurance)</td>\n",
       "      <td>Baljeeta</td>\n",
       "      <td>2024-03-22 10:51:07</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meltemsprtl/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Meltem SUPURTULU</td>\n",
       "      <td>2022-02-09 07:51:36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abdul3344/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Abdul3344</td>\n",
       "      <td>2022-11-07 17:17:21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mustiztemiz/linear-regression-house-rice-predi...</td>\n",
       "      <td>Linear_Regression _House_rice_prediction</td>\n",
       "      <td>mustafa öztemiz</td>\n",
       "      <td>2021-11-12 17:16:49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rashmiek99/head-size-vs-brain-weight</td>\n",
       "      <td>Head Size Vs Brain Weight</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>2019-08-01 01:03:35</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aiyoweidtt/linear-regression-decision-tree-ran...</td>\n",
       "      <td>Linear_Regression/Decision_Tree/Random_Forest</td>\n",
       "      <td>Aiyowei</td>\n",
       "      <td>2019-08-22 08:50:50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ajcostarino/ingv-volcanic-eruption-prediction-...</td>\n",
       "      <td>INGV Volcanic Eruption Prediction - LGBM Base...</td>\n",
       "      <td>Adam James</td>\n",
       "      <td>2020-12-15 21:35:13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ref  \\\n",
       "1                        hakmatkhan/linear-regression   \n",
       "2                          sanket82/linear-regression   \n",
       "3   nkitgupta/feature-engineering-and-feature-sele...   \n",
       "4        baljeeta/linear-regression-medical-insurance   \n",
       "5                       meltemsprtl/linear-regression   \n",
       "6                         abdul3344/linear-regression   \n",
       "7   mustiztemiz/linear-regression-house-rice-predi...   \n",
       "8                rashmiek99/head-size-vs-brain-weight   \n",
       "9   aiyoweidtt/linear-regression-decision-tree-ran...   \n",
       "10  ajcostarino/ingv-volcanic-eruption-prediction-...   \n",
       "\n",
       "                                                title            author  \\\n",
       "1                                   Linear_regression       Hakmat khan   \n",
       "2                                   Linear_Regression  Sanket Adamapure   \n",
       "3           Feature Engineering and Feature Selection       Ankit Gupta   \n",
       "4                Linear_regression(Medical_Insurance)          Baljeeta   \n",
       "5                                   linear_regression  Meltem SUPURTULU   \n",
       "6                                   Linear_Regression         Abdul3344   \n",
       "7            Linear_Regression _House_rice_prediction   mustafa öztemiz   \n",
       "8                           Head Size Vs Brain Weight            Rashmi   \n",
       "9       Linear_Regression/Decision_Tree/Random_Forest           Aiyowei   \n",
       "10   INGV Volcanic Eruption Prediction - LGBM Base...        Adam James   \n",
       "\n",
       "            lastRunTime totalVotes  \n",
       "1   2023-01-05 15:30:05          2  \n",
       "2   2022-01-30 17:04:53          2  \n",
       "3   2022-04-28 13:34:32        172  \n",
       "4   2024-03-22 10:51:07          6  \n",
       "5   2022-02-09 07:51:36          3  \n",
       "6   2022-11-07 17:17:21          3  \n",
       "7   2021-11-12 17:16:49          5  \n",
       "8   2019-08-01 01:03:35         24  \n",
       "9   2019-08-22 08:50:50          3  \n",
       "10  2020-12-15 21:35:13         47  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos para mostrar los 10 primeros resultados de la lista notebooks en un DataFrame\n",
    "notebooks2=[]         #Nueva lista vacía\n",
    "d=len(notebooks)      #Numero de elementos de la lista notebooks\n",
    "r=range(0,d)          #Rango para la iteracion\n",
    "for i in r:                                    #Ciclo repetitivo para recorrer toda la lista notebooks\n",
    "    notebooks_split=notebooks[i].split(',',4)  #Se separan los elementos de cada posicion de la lista notebooks\n",
    "    notebooks2.append(notebooks_split)         #Se añade cada lista de elementos separados en la lista notebooks2\n",
    "notebooks_DF=pd.DataFrame(notebooks2, columns=notebooks2[0])  #Se transforma en dataframe la lista notebooks2 (lista de listas)\n",
    "notebooks_DF[1:11]                             #Se muestran los primeros 10 resultados de los notebooks, sin incluir los resultados para las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>algosforgood/kiva-understanding-poverty-levels...</td>\n",
       "      <td>Kiva - Understanding Poverty Levels of Borrowers</td>\n",
       "      <td>AlgosForGood</td>\n",
       "      <td>2018-03-06 22:17:55</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>marshuu/poverty-rate-in-the-us-animation</td>\n",
       "      <td>Poverty rate in the US (animation)</td>\n",
       "      <td>Maryna Shut</td>\n",
       "      <td>2023-01-08 11:12:33</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ayushimishra2809/covid-19-visualizations-and-p...</td>\n",
       "      <td>COVID 19- Visualizations and Predictions</td>\n",
       "      <td>Ayushi Mishra</td>\n",
       "      <td>2020-03-20 14:33:57</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>mhjudi/poverty-data</td>\n",
       "      <td>Poverty Data</td>\n",
       "      <td>Mohamed Judi</td>\n",
       "      <td>2018-04-07 04:03:48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>pranav2109/featureengineering-ensemble-xgbpipe...</td>\n",
       "      <td>FeatureEngineering+Ensemble-XGBPipeline</td>\n",
       "      <td>Pranav Agarwal</td>\n",
       "      <td>2021-08-27 02:25:42</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>urbanmonk09/example-simple-imputer</td>\n",
       "      <td>example simple imputer</td>\n",
       "      <td>Urban Monk 09</td>\n",
       "      <td>2024-04-30 04:12:24</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>bryanteh/covid19-sigmoidmodel</td>\n",
       "      <td>Covid19_SigmoidModel</td>\n",
       "      <td>Bryan Teh Yu Qi</td>\n",
       "      <td>2020-04-12 05:10:36</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ragnisah/eda-abalone-age-prediction</td>\n",
       "      <td>EDA- Abalone Age Prediction</td>\n",
       "      <td>Rageeni Sah</td>\n",
       "      <td>2019-08-28 05:49:01</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>shearerp/interactive-sales-visualization</td>\n",
       "      <td>Interactive Sales Visualization!</td>\n",
       "      <td>PaulShearer</td>\n",
       "      <td>2015-10-29 18:29:23</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>vadimkamaev/icr-identify-age</td>\n",
       "      <td>icr-identify-age</td>\n",
       "      <td>Vadim Kamaev</td>\n",
       "      <td>2023-06-11 06:17:12</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "101  algosforgood/kiva-understanding-poverty-levels...   \n",
       "90            marshuu/poverty-rate-in-the-us-animation   \n",
       "157  ayushimishra2809/covid-19-visualizations-and-p...   \n",
       "116                                mhjudi/poverty-data   \n",
       "215  pranav2109/featureengineering-ensemble-xgbpipe...   \n",
       "211                 urbanmonk09/example-simple-imputer   \n",
       "140                      bryanteh/covid19-sigmoidmodel   \n",
       "210                ragnisah/eda-abalone-age-prediction   \n",
       "53            shearerp/interactive-sales-visualization   \n",
       "199                       vadimkamaev/icr-identify-age   \n",
       "\n",
       "                                                title           author  \\\n",
       "101  Kiva - Understanding Poverty Levels of Borrowers     AlgosForGood   \n",
       "90                 Poverty rate in the US (animation)      Maryna Shut   \n",
       "157          COVID 19- Visualizations and Predictions    Ayushi Mishra   \n",
       "116                                      Poverty Data     Mohamed Judi   \n",
       "215           FeatureEngineering+Ensemble-XGBPipeline   Pranav Agarwal   \n",
       "211                            example simple imputer    Urban Monk 09   \n",
       "140                              Covid19_SigmoidModel  Bryan Teh Yu Qi   \n",
       "210                       EDA- Abalone Age Prediction      Rageeni Sah   \n",
       "53                   Interactive Sales Visualization!      PaulShearer   \n",
       "199                                  icr-identify-age     Vadim Kamaev   \n",
       "\n",
       "             lastRunTime totalVotes  \n",
       "101  2018-03-06 22:17:55         14  \n",
       "90   2023-01-08 11:12:33         35  \n",
       "157  2020-03-20 14:33:57         28  \n",
       "116  2018-04-07 04:03:48          2  \n",
       "215  2021-08-27 02:25:42         67  \n",
       "211  2024-04-30 04:12:24         18  \n",
       "140  2020-04-12 05:10:36          7  \n",
       "210  2019-08-28 05:49:01         65  \n",
       "53   2015-10-29 18:29:23        115  \n",
       "199  2023-06-11 06:17:12        140  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_DF.sample(10)                        #Se muestran 10 resultados al azar de los notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZziTCBZaZCK"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 5 (1.75 puntos): Limpieza de metadatos de notebooks.</b>\n",
    "\n",
    "<b>Objetivo:</b> Limpiar los metadatos de notebooks de tal manera que no hayan elementos duplicados, ni hayan datos con valores inesperados.\n",
    "\n",
    "<b>Contexto:</b> Algunos notebooks también pueden repetirse como se ha explicado previamente.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer la lista de resultados <i> notebooks </i> y dejar solo resultados únicos de notebooks.\n",
    "- Explorar los resultados obtenidos para verificar que los datos no contienen caracteres o elementos extraños.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros notebooks únicos que han sido procesados.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EVuR-RaaaZCK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con valores nulos por columnas:\n",
      "ref             0\n",
      "title          13\n",
      "author         13\n",
      "lastRunTime    13\n",
      "totalVotes     13\n",
      "dtype: int64\n",
      "\n",
      "DataFrame con valores nulos por filas:\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "      ..\n",
      "226    0\n",
      "227    4\n",
      "228    0\n",
      "229    4\n",
      "230    4\n",
      "Length: 230, dtype: int64\n",
      "\n",
      "DataFrame solamente con las filas nulas:\n",
      "18     4\n",
      "19     4\n",
      "25     4\n",
      "125    4\n",
      "147    4\n",
      "164    4\n",
      "166    4\n",
      "176    4\n",
      "190    4\n",
      "201    4\n",
      "227    4\n",
      "229    4\n",
      "230    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "#Para la solucion se decide trabajar con los resultados obtenidos de los notebooks en formato DataFrame\n",
    "\n",
    "#a.) Eliminación de los resultados duplicados del Dataframe\n",
    "notebooks_DF_p=notebooks_DF.drop_duplicates()                    #Se utiliza drop_duplicates() para eliminar las filas duplicadas\n",
    "notebooks_DF_pp=notebooks_DF_p.drop([0],axis=0)                  #Se elimina la primera fila que corresponde con los nombres de las columnas.\n",
    "notebooks_DF_pp.index=range(1,len(notebooks_DF_pp)+1)            #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_inicial=len(notebooks_DF)                              #Se utiliza len para medir el tamaño del DataFrame sin procesar\n",
    "dimension_sin_duplicados=len(notebooks_DF_pp)                    #Se utiliza len para medir el tamaño del DataFrame preprocesado\n",
    "cantidad_duplicados=dimension_inicial-dimension_sin_duplicados   #Se calcula la cantidad de elementos duplicados\n",
    "\n",
    "#b.) Verificar si hay valores inesperados\n",
    "valores_null_columnas=notebooks_DF_pp.isnull().sum()             #Se guarda en un DataFrame el numero de valores nulos por columnas\n",
    "valores_null_filas=(notebooks_DF_pp.isnull().sum(axis=1))        #Se guarda en un DataFrame el numero de valores nulos por filas\n",
    "\n",
    "filas_nulas=[]                                                   #Lista vacia para almacenar las filas nulas                   \n",
    "for j in range(1,len(valores_null_filas)+1):                     #Ciclo repetitivo para recorrer el DataFrame con el numero de valores nulos por filas\n",
    "    if valores_null_filas[j]!=0:                                 #Cuando el valor de la fila es distinto de cero se añade en la lista \n",
    "        filas_nulas.append(j)\n",
    "valores_null_filas_filtradas=valores_null_filas[filas_nulas]     #Dataframe solamente con las filas nulas\n",
    "\n",
    "print(\"DataFrame con valores nulos por columnas:\")               #Se imprime el DataFrame con el numero de valores nulos por columnas\n",
    "print(valores_null_columnas)\n",
    "print(\"\\nDataFrame con valores nulos por filas:\")                #Se imprime el DataFrame con el numero de valores nulos por filas\n",
    "print(valores_null_filas)\n",
    "print(\"\\nDataFrame solamente con las filas nulas:\")              #Se imprimen el Dataframe anterior solamente con las filas nulas\n",
    "print(valores_null_filas_filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De  acuerdo al analisis anterior existen 13 filas con valores nulos. Las cuales tienen vacias todas sus columnas a excepcion de la primera\n",
    "#Se decide eliminar estas filas \n",
    "\n",
    "notebooks_DF_prep=notebooks_DF_pp.drop(filas_nulas,axis=0)       #Se eliminan las filas con valores nulos\n",
    "notebooks_DF_prep.index=range(1,len(notebooks_DF_prep)+1)        #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_final=len(notebooks_DF_prep)                           #Se utiliza len para medir el tamaño del DataFrame preprocesado final\n",
    "filas_eliminadas_vacias=len(filas_nulas)                         #Se utiliza len para medir el tamaño de filas eliminadas\n",
    "cantidad_filas_eliminadas=dimension_inicial-dimension_final      #Se calcula la cantidad de elementos eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension inicial del Dataframe: 251\n",
      "Dimension del Dataframe sin elementos duplicados: 230\n",
      "Cantidad de filas duplicadas: 21\n",
      "Dimension del DataFrame con datos únicos preprocesados: 217\n",
      "Cantidad de filas eliminadas vacias: 13\n",
      "Cantidad total de filas eliminadas: 34\n",
      "\n",
      "Dataframe con datos únicos preprocesados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hakmatkhan/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>Hakmat khan</td>\n",
       "      <td>2023-01-05 15:30:05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanket82/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Sanket Adamapure</td>\n",
       "      <td>2022-01-30 17:04:53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nkitgupta/feature-engineering-and-feature-sele...</td>\n",
       "      <td>Feature Engineering and Feature Selection</td>\n",
       "      <td>Ankit Gupta</td>\n",
       "      <td>2022-04-28 13:34:32</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baljeeta/linear-regression-medical-insurance</td>\n",
       "      <td>Linear_regression(Medical_Insurance)</td>\n",
       "      <td>Baljeeta</td>\n",
       "      <td>2024-03-22 10:51:07</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meltemsprtl/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Meltem SUPURTULU</td>\n",
       "      <td>2022-02-09 07:51:36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abdul3344/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Abdul3344</td>\n",
       "      <td>2022-11-07 17:17:21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mustiztemiz/linear-regression-house-rice-predi...</td>\n",
       "      <td>Linear_Regression _House_rice_prediction</td>\n",
       "      <td>mustafa öztemiz</td>\n",
       "      <td>2021-11-12 17:16:49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rashmiek99/head-size-vs-brain-weight</td>\n",
       "      <td>Head Size Vs Brain Weight</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>2019-08-01 01:03:35</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aiyoweidtt/linear-regression-decision-tree-ran...</td>\n",
       "      <td>Linear_Regression/Decision_Tree/Random_Forest</td>\n",
       "      <td>Aiyowei</td>\n",
       "      <td>2019-08-22 08:50:50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ajcostarino/ingv-volcanic-eruption-prediction-...</td>\n",
       "      <td>INGV Volcanic Eruption Prediction - LGBM Base...</td>\n",
       "      <td>Adam James</td>\n",
       "      <td>2020-12-15 21:35:13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ref  \\\n",
       "1                        hakmatkhan/linear-regression   \n",
       "2                          sanket82/linear-regression   \n",
       "3   nkitgupta/feature-engineering-and-feature-sele...   \n",
       "4        baljeeta/linear-regression-medical-insurance   \n",
       "5                       meltemsprtl/linear-regression   \n",
       "6                         abdul3344/linear-regression   \n",
       "7   mustiztemiz/linear-regression-house-rice-predi...   \n",
       "8                rashmiek99/head-size-vs-brain-weight   \n",
       "9   aiyoweidtt/linear-regression-decision-tree-ran...   \n",
       "10  ajcostarino/ingv-volcanic-eruption-prediction-...   \n",
       "\n",
       "                                                title            author  \\\n",
       "1                                   Linear_regression       Hakmat khan   \n",
       "2                                   Linear_Regression  Sanket Adamapure   \n",
       "3           Feature Engineering and Feature Selection       Ankit Gupta   \n",
       "4                Linear_regression(Medical_Insurance)          Baljeeta   \n",
       "5                                   linear_regression  Meltem SUPURTULU   \n",
       "6                                   Linear_Regression         Abdul3344   \n",
       "7            Linear_Regression _House_rice_prediction   mustafa öztemiz   \n",
       "8                           Head Size Vs Brain Weight            Rashmi   \n",
       "9       Linear_Regression/Decision_Tree/Random_Forest           Aiyowei   \n",
       "10   INGV Volcanic Eruption Prediction - LGBM Base...        Adam James   \n",
       "\n",
       "            lastRunTime totalVotes  \n",
       "1   2023-01-05 15:30:05          2  \n",
       "2   2022-01-30 17:04:53          2  \n",
       "3   2022-04-28 13:34:32        172  \n",
       "4   2024-03-22 10:51:07          6  \n",
       "5   2022-02-09 07:51:36          3  \n",
       "6   2022-11-07 17:17:21          3  \n",
       "7   2021-11-12 17:16:49          5  \n",
       "8   2019-08-01 01:03:35         24  \n",
       "9   2019-08-22 08:50:50          3  \n",
       "10  2020-12-15 21:35:13         47  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c.) Impresion de resultados\n",
    "print(\"Dimension inicial del Dataframe:\",dimension_inicial)      #Se imprime el tamaño del DataFrame sin procesar\n",
    "print(\"Dimension del Dataframe sin elementos duplicados:\",dimension_sin_duplicados) #Se imprime el tamaño del DataFrame preprocesado\n",
    "print(\"Cantidad de filas duplicadas:\",cantidad_duplicados)       #Se imprime la cantidad de elementos duplicados\n",
    "print(\"Dimension del DataFrame con datos únicos preprocesados:\",dimension_final)    #Se imprime la cantidad de elementos del DataFrame preprocesado final\n",
    "print(\"Cantidad de filas eliminadas vacias:\",filas_eliminadas_vacias)   #Se imprime la cantidad de filas_eliminadas que estaban vacías\n",
    "print(\"Cantidad total de filas eliminadas:\",cantidad_filas_eliminadas)  #Se imprime la cantidad total de filas eliminadas\n",
    "print(\"\\nDataframe con datos únicos preprocesados:\")                           \n",
    "notebooks_DF_prep[:10]                                            #Se imprimen los 10 primeros resultados del DataFrame preprocesado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>siddheshpujari/eda-and-prediction-of-house-price</td>\n",
       "      <td>EDA and Prediction of House Price</td>\n",
       "      <td>Siddhesh Pujari</td>\n",
       "      <td>2020-06-06 08:58:05</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>namanmanchanda/heart-attack-eda-prediction-90-...</td>\n",
       "      <td>Heart Attack - EDA + Prediction (90% accuracy)</td>\n",
       "      <td>Naman Manchanda</td>\n",
       "      <td>2021-05-22 11:44:42</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yashvi/data-analyst-jobs-visualization</td>\n",
       "      <td>Data analyst jobs visualization</td>\n",
       "      <td>Yashvi Patel</td>\n",
       "      <td>2020-07-26 07:05:54</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>jroachel/how-poverty-and-trade-impact-carbon-f...</td>\n",
       "      <td>How Poverty and Trade Impact Carbon Footprint</td>\n",
       "      <td>Jianyin R.</td>\n",
       "      <td>2018-11-19 00:52:13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>opamusora/optimized-0-06</td>\n",
       "      <td>Optimized 0.06</td>\n",
       "      <td>opamusora (Ivan Viakhirev)</td>\n",
       "      <td>2023-07-09 13:45:03</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>niteshdandale/eda-and-linear-regression</td>\n",
       "      <td>EDA and Linear_Regression</td>\n",
       "      <td>Nitesh Dandale</td>\n",
       "      <td>2022-05-25 15:02:19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>vaibhavjain2004/public-krni-pdi</td>\n",
       "      <td>public_krni_pdi_:(</td>\n",
       "      <td>Vaibhav Jain</td>\n",
       "      <td>2023-06-18 14:22:36</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>vprokopev/mean-likelihood-encodings-a-comprehe...</td>\n",
       "      <td>Mean (likelihood) encodings: a comprehensive s...</td>\n",
       "      <td>Viacheslav Prokopev</td>\n",
       "      <td>2018-10-07 19:38:25</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>chemaplana/some-poverty-charts</td>\n",
       "      <td>Some poverty charts</td>\n",
       "      <td>Chema Plana</td>\n",
       "      <td>2017-11-25 09:32:23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>vadimkamaev/icr-identify-age</td>\n",
       "      <td>icr-identify-age</td>\n",
       "      <td>Vadim Kamaev</td>\n",
       "      <td>2023-06-11 06:17:12</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "196   siddheshpujari/eda-and-prediction-of-house-price   \n",
       "164  namanmanchanda/heart-attack-eda-prediction-90-...   \n",
       "43              yashvi/data-analyst-jobs-visualization   \n",
       "97   jroachel/how-poverty-and-trade-impact-carbon-f...   \n",
       "209                           opamusora/optimized-0-06   \n",
       "16             niteshdandale/eda-and-linear-regression   \n",
       "173                    vaibhavjain2004/public-krni-pdi   \n",
       "74   vprokopev/mean-likelihood-encodings-a-comprehe...   \n",
       "116                     chemaplana/some-poverty-charts   \n",
       "176                       vadimkamaev/icr-identify-age   \n",
       "\n",
       "                                                 title  \\\n",
       "196                 EDA and Prediction of House Price    \n",
       "164     Heart Attack - EDA + Prediction (90% accuracy)   \n",
       "43                    Data analyst jobs visualization    \n",
       "97       How Poverty and Trade Impact Carbon Footprint   \n",
       "209                                     Optimized 0.06   \n",
       "16                           EDA and Linear_Regression   \n",
       "173                                 public_krni_pdi_:(   \n",
       "74   Mean (likelihood) encodings: a comprehensive s...   \n",
       "116                                Some poverty charts   \n",
       "176                                   icr-identify-age   \n",
       "\n",
       "                         author          lastRunTime totalVotes  \n",
       "196             Siddhesh Pujari  2020-06-06 08:58:05         71  \n",
       "164             Naman Manchanda  2021-05-22 11:44:42        435  \n",
       "43                 Yashvi Patel  2020-07-26 07:05:54        173  \n",
       "97                   Jianyin R.  2018-11-19 00:52:13          8  \n",
       "209  opamusora (Ivan Viakhirev)  2023-07-09 13:45:03         39  \n",
       "16               Nitesh Dandale  2022-05-25 15:02:19          3  \n",
       "173                Vaibhav Jain  2023-06-18 14:22:36        111  \n",
       "74          Viacheslav Prokopev  2018-10-07 19:38:25        291  \n",
       "116                 Chema Plana  2017-11-25 09:32:23          3  \n",
       "176                Vadim Kamaev  2023-06-11 06:17:12        140  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_DF_prep.sample(10)                                      #Se muestran 10 resultados al azar del DataFrame preprocesado final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xmoduncaZCL"
   },
   "source": [
    "### Paso 2.2: Integración de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6F8KNJuaZCL"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 6 (2 ptos): Integración de datos obtenidos (tanto de datasets y notebooks) </b>\n",
    "\n",
    "<b>Objetivo:</b> Crear un dataframe único donde consten los datos de los datasets como de los notebooks.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- A partir de la estructuras de datos <i> datasets </i> y <i> notebooks </i>, determinar cuáles los atributos comunes y cuáles son diferentes para crear una sola estructura tipo dataframe que almacene todos los datos extraídos.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar un <i>sample</i> de 10 elementos que consten en el dataframe único\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dwgU4fEkaZCM"
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "#Se decide añadir una columna de 'Tipo' o 'Type' para identificar a los Datasets y a los Notebooks.\n",
    "def palabraDataset(arg1):         #Funcion para obtener la palabra 'Dataset'\n",
    "    palabra=\"Dataset\"\n",
    "    return palabra\n",
    "\n",
    "def palabraNotebook(arg2):        #Funcion para obtener la palabra 'Notebook'\n",
    "    palabra=\"Notebook\"\n",
    "    return palabra\n",
    "\n",
    "datasets_DF_prep['type'] = datasets_DF_prep['ref'].apply(palabraDataset)        #Se añade la columna 'type' en el DataFrame Datasets\n",
    "notebooks_DF_prep['type'] = notebooks_DF_prep['ref'].apply(palabraNotebook)     #Se añade la columna 'type' en el DataFrame Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>l10677832/outliers</td>\n",
       "      <td>outliers</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2023-11-13 12:11:04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>nihalbarua/dota2-competitive-picks</td>\n",
       "      <td>Dota 2 Competitive Picks</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2024-02-28 08:34:11</td>\n",
       "      <td>623</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>krantiswalke/bankfullcsv</td>\n",
       "      <td>bank-full.csv (Ensemble Techniques)</td>\n",
       "      <td>481KB</td>\n",
       "      <td>2020-04-23 08:21:57</td>\n",
       "      <td>7999</td>\n",
       "      <td>48</td>\n",
       "      <td>0.64705884</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>chandramoulinaidu/house-price-prediction-clean...</td>\n",
       "      <td>House Price Prediction Cleaned Dataset</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2021-03-12 06:18:35</td>\n",
       "      <td>1011</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9411765</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tamatoa/myimg</td>\n",
       "      <td>outliers</td>\n",
       "      <td>84KB</td>\n",
       "      <td>2017-11-04 11:52:35</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "1                        aml0ali2000/linear-regression   \n",
       "2                    kasiviswanath00/linear-regression   \n",
       "3                   drakedyban/mediumlinear-regression   \n",
       "4                 sangitamule/linear-regressionproject   \n",
       "5                 krishnamohanmaurya/linear-regression   \n",
       "..                                                 ...   \n",
       "280                                 l10677832/outliers   \n",
       "281                 nihalbarua/dota2-competitive-picks   \n",
       "282                           krantiswalke/bankfullcsv   \n",
       "283  chandramoulinaidu/house-price-prediction-clean...   \n",
       "284                                      tamatoa/myimg   \n",
       "\n",
       "                                      title   size          lastUpdated  \\\n",
       "1                         Linear_regression    1KB  2023-12-04 14:34:14   \n",
       "2                         linear_regression   378B  2022-05-25 12:08:15   \n",
       "3                  Medium-Linear_Regression    5KB  2021-02-28 22:37:25   \n",
       "4                /Linear_Regression-Project   40KB  2022-02-03 06:41:39   \n",
       "5                         Linear_Regression    5KB  2023-02-27 14:38:50   \n",
       "..                                      ...    ...                  ...   \n",
       "280                                outliers    2MB  2023-11-13 12:11:04   \n",
       "281                Dota 2 Competitive Picks    5KB  2024-02-28 08:34:11   \n",
       "282     bank-full.csv (Ensemble Techniques)  481KB  2020-04-23 08:21:57   \n",
       "283  House Price Prediction Cleaned Dataset    1MB  2021-03-12 06:18:35   \n",
       "284                                outliers   84KB  2017-11-04 11:52:35   \n",
       "\n",
       "    downloadCount voteCount usabilityRating     type  \n",
       "1               7         2       0.3529412  Dataset  \n",
       "2              15         2       0.1764706  Dataset  \n",
       "3              19         1          0.4375  Dataset  \n",
       "4              14         2      0.29411766  Dataset  \n",
       "5               7         2       0.1764706  Dataset  \n",
       "..            ...       ...             ...      ...  \n",
       "280             1         1            0.25  Dataset  \n",
       "281           623        41             1.0  Dataset  \n",
       "282          7999        48      0.64705884  Dataset  \n",
       "283          1011        11       0.9411765  Dataset  \n",
       "284            37         0          0.4375  Dataset  \n",
       "\n",
       "[284 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_DF_prep                               #Se imprime el DataFrame Datasets para verificar el cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hakmatkhan/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>Hakmat khan</td>\n",
       "      <td>2023-01-05 15:30:05</td>\n",
       "      <td>2</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanket82/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Sanket Adamapure</td>\n",
       "      <td>2022-01-30 17:04:53</td>\n",
       "      <td>2</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nkitgupta/feature-engineering-and-feature-sele...</td>\n",
       "      <td>Feature Engineering and Feature Selection</td>\n",
       "      <td>Ankit Gupta</td>\n",
       "      <td>2022-04-28 13:34:32</td>\n",
       "      <td>172</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baljeeta/linear-regression-medical-insurance</td>\n",
       "      <td>Linear_regression(Medical_Insurance)</td>\n",
       "      <td>Baljeeta</td>\n",
       "      <td>2024-03-22 10:51:07</td>\n",
       "      <td>6</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meltemsprtl/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Meltem SUPURTULU</td>\n",
       "      <td>2022-02-09 07:51:36</td>\n",
       "      <td>3</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>aharless/xgb-w-o-outliers-lgb-with-outliers-co...</td>\n",
       "      <td>XGB w/o outliers &amp; LGB with outliers combined</td>\n",
       "      <td>Andy Harless</td>\n",
       "      <td>2017-07-18 02:21:21</td>\n",
       "      <td>95</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>junjitakeshima/ubiquant-simple-lgbm-removing-o...</td>\n",
       "      <td>[Ubiquant] Simple LGBM removing Outliers (En/Jp)</td>\n",
       "      <td>Junji Takeshima</td>\n",
       "      <td>2022-02-23 07:20:06</td>\n",
       "      <td>106</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>sudalairajkumar/rainfall-test</td>\n",
       "      <td>Beware of Outliers !!</td>\n",
       "      <td>SRK</td>\n",
       "      <td>2015-09-18 01:38:17</td>\n",
       "      <td>45</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>miklgr500/ghost-drift-and-outliers</td>\n",
       "      <td>\"\"\"Ghost\"\" drift and Outliers\"</td>\n",
       "      <td>Welf Crozzo</td>\n",
       "      <td>2020-04-12 06:25:26</td>\n",
       "      <td>64</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>yassineghouzam/titanic-top-4-with-ensemble-mod...</td>\n",
       "      <td>Titanic Top 4% with ensemble modeling</td>\n",
       "      <td>Yassine Ghouzam</td>\n",
       "      <td>2023-11-22 19:13:03</td>\n",
       "      <td>2892</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "1                         hakmatkhan/linear-regression   \n",
       "2                           sanket82/linear-regression   \n",
       "3    nkitgupta/feature-engineering-and-feature-sele...   \n",
       "4         baljeeta/linear-regression-medical-insurance   \n",
       "5                        meltemsprtl/linear-regression   \n",
       "..                                                 ...   \n",
       "213  aharless/xgb-w-o-outliers-lgb-with-outliers-co...   \n",
       "214  junjitakeshima/ubiquant-simple-lgbm-removing-o...   \n",
       "215                      sudalairajkumar/rainfall-test   \n",
       "216                 miklgr500/ghost-drift-and-outliers   \n",
       "217  yassineghouzam/titanic-top-4-with-ensemble-mod...   \n",
       "\n",
       "                                                title            author  \\\n",
       "1                                   Linear_regression       Hakmat khan   \n",
       "2                                   Linear_Regression  Sanket Adamapure   \n",
       "3           Feature Engineering and Feature Selection       Ankit Gupta   \n",
       "4                Linear_regression(Medical_Insurance)          Baljeeta   \n",
       "5                                   linear_regression  Meltem SUPURTULU   \n",
       "..                                                ...               ...   \n",
       "213     XGB w/o outliers & LGB with outliers combined      Andy Harless   \n",
       "214  [Ubiquant] Simple LGBM removing Outliers (En/Jp)   Junji Takeshima   \n",
       "215                             Beware of Outliers !!               SRK   \n",
       "216                    \"\"\"Ghost\"\" drift and Outliers\"       Welf Crozzo   \n",
       "217             Titanic Top 4% with ensemble modeling   Yassine Ghouzam   \n",
       "\n",
       "             lastRunTime totalVotes      type  \n",
       "1    2023-01-05 15:30:05          2  Notebook  \n",
       "2    2022-01-30 17:04:53          2  Notebook  \n",
       "3    2022-04-28 13:34:32        172  Notebook  \n",
       "4    2024-03-22 10:51:07          6  Notebook  \n",
       "5    2022-02-09 07:51:36          3  Notebook  \n",
       "..                   ...        ...       ...  \n",
       "213  2017-07-18 02:21:21         95  Notebook  \n",
       "214  2022-02-23 07:20:06        106  Notebook  \n",
       "215  2015-09-18 01:38:17         45  Notebook  \n",
       "216  2020-04-12 06:25:26         64  Notebook  \n",
       "217  2023-11-22 19:13:03       2892  Notebook  \n",
       "\n",
       "[217 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_DF_prep                              #Se imprime el DataFrame Notebooks para verificar el cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>aharless/xgb-w-o-outliers-lgb-with-outliers-co...</td>\n",
       "      <td>XGB w/o outliers &amp; LGB with outliers combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andy Harless</td>\n",
       "      <td>2017-07-18 02:21:21</td>\n",
       "      <td>95</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>junjitakeshima/ubiquant-simple-lgbm-removing-o...</td>\n",
       "      <td>[Ubiquant] Simple LGBM removing Outliers (En/Jp)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junji Takeshima</td>\n",
       "      <td>2022-02-23 07:20:06</td>\n",
       "      <td>106</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>sudalairajkumar/rainfall-test</td>\n",
       "      <td>Beware of Outliers !!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRK</td>\n",
       "      <td>2015-09-18 01:38:17</td>\n",
       "      <td>45</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>miklgr500/ghost-drift-and-outliers</td>\n",
       "      <td>\"\"\"Ghost\"\" drift and Outliers\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Welf Crozzo</td>\n",
       "      <td>2020-04-12 06:25:26</td>\n",
       "      <td>64</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>yassineghouzam/titanic-top-4-with-ensemble-mod...</td>\n",
       "      <td>Titanic Top 4% with ensemble modeling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yassine Ghouzam</td>\n",
       "      <td>2023-11-22 19:13:03</td>\n",
       "      <td>2892</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "1                        aml0ali2000/linear-regression   \n",
       "2                    kasiviswanath00/linear-regression   \n",
       "3                   drakedyban/mediumlinear-regression   \n",
       "4                 sangitamule/linear-regressionproject   \n",
       "5                 krishnamohanmaurya/linear-regression   \n",
       "..                                                 ...   \n",
       "497  aharless/xgb-w-o-outliers-lgb-with-outliers-co...   \n",
       "498  junjitakeshima/ubiquant-simple-lgbm-removing-o...   \n",
       "499                      sudalairajkumar/rainfall-test   \n",
       "500                 miklgr500/ghost-drift-and-outliers   \n",
       "501  yassineghouzam/titanic-top-4-with-ensemble-mod...   \n",
       "\n",
       "                                                title  size  \\\n",
       "1                                   Linear_regression   1KB   \n",
       "2                                   linear_regression  378B   \n",
       "3                            Medium-Linear_Regression   5KB   \n",
       "4                          /Linear_Regression-Project  40KB   \n",
       "5                                   Linear_Regression   5KB   \n",
       "..                                                ...   ...   \n",
       "497     XGB w/o outliers & LGB with outliers combined   NaN   \n",
       "498  [Ubiquant] Simple LGBM removing Outliers (En/Jp)   NaN   \n",
       "499                             Beware of Outliers !!   NaN   \n",
       "500                    \"\"\"Ghost\"\" drift and Outliers\"   NaN   \n",
       "501             Titanic Top 4% with ensemble modeling   NaN   \n",
       "\n",
       "             lastUpdated downloadCount voteCount usabilityRating  \\\n",
       "1    2023-12-04 14:34:14             7         2       0.3529412   \n",
       "2    2022-05-25 12:08:15            15         2       0.1764706   \n",
       "3    2021-02-28 22:37:25            19         1          0.4375   \n",
       "4    2022-02-03 06:41:39            14         2      0.29411766   \n",
       "5    2023-02-27 14:38:50             7         2       0.1764706   \n",
       "..                   ...           ...       ...             ...   \n",
       "497                  NaN           NaN       NaN             NaN   \n",
       "498                  NaN           NaN       NaN             NaN   \n",
       "499                  NaN           NaN       NaN             NaN   \n",
       "500                  NaN           NaN       NaN             NaN   \n",
       "501                  NaN           NaN       NaN             NaN   \n",
       "\n",
       "              author          lastRunTime totalVotes      type  \n",
       "1                NaN                  NaN        NaN   Dataset  \n",
       "2                NaN                  NaN        NaN   Dataset  \n",
       "3                NaN                  NaN        NaN   Dataset  \n",
       "4                NaN                  NaN        NaN   Dataset  \n",
       "5                NaN                  NaN        NaN   Dataset  \n",
       "..               ...                  ...        ...       ...  \n",
       "497     Andy Harless  2017-07-18 02:21:21         95  Notebook  \n",
       "498  Junji Takeshima  2022-02-23 07:20:06        106  Notebook  \n",
       "499              SRK  2015-09-18 01:38:17         45  Notebook  \n",
       "500      Welf Crozzo  2020-04-12 06:25:26         64  Notebook  \n",
       "501  Yassine Ghouzam  2023-11-22 19:13:03       2892  Notebook  \n",
       "\n",
       "[501 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#De acuerdo a los DataFrames de Datasets y de Notebooks se puede afirmar lo siguiente:\n",
    "####Columnas en común: 'ref' y 'title'\n",
    "####Columnas distintas: Datasets (size, lastUpdated, downloadCount, voteCount, usabilityRating)\n",
    "####Columnas distintas: Notebooks (author, lastRunTime, totalVotes)\n",
    "\n",
    "#Se unen los DataFrames de los Datasets y de los Notebooks\n",
    "#Se unen por medios de las filas\n",
    "#Las columnas distintas de cada DataFrame llenan automáticamente como valores vacíos (NaN)\n",
    "DataFrame_Unido=pd.concat([datasets_DF_prep, notebooks_DF_prep])  #Se utiliza el metodo concat para unir los DataFrames\n",
    "DataFrame_Unido.index=range(1,len(DataFrame_Unido)+1)             #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "DataFrame_Unido = DataFrame_Unido[[col for col in DataFrame_Unido.columns if col != 'type'] + ['type']]  #Se mueve la columna 'type' al final\n",
    "DataFrame_Unido                                                   #Se imprime el DataFrame unido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>hemil26/nft-collections-dataset</td>\n",
       "      <td>NFT Collections</td>\n",
       "      <td>7KB</td>\n",
       "      <td>2022-10-02 08:36:49</td>\n",
       "      <td>2667</td>\n",
       "      <td>129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>arjundas/simpleanalysis-for-kiva-its-time-for-...</td>\n",
       "      <td>SimpleAnalysis for KIVA (Its time for Africa!!!)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADM</td>\n",
       "      <td>2018-05-12 05:57:27</td>\n",
       "      <td>170</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>lakshyaag/india-trade-data</td>\n",
       "      <td>India - Trade Data</td>\n",
       "      <td>3MB</td>\n",
       "      <td>2022-11-02 07:31:00</td>\n",
       "      <td>25081</td>\n",
       "      <td>453</td>\n",
       "      <td>0.9705882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>ash316/eda-to-prediction-dietanic</td>\n",
       "      <td>EDA To Prediction(DieTanic)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashwini Swain</td>\n",
       "      <td>2018-03-08 17:55:32</td>\n",
       "      <td>2952</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>inversion/get-started-with-mean-imputation</td>\n",
       "      <td>Get Started with Mean Imputation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inversion</td>\n",
       "      <td>2022-05-26 20:55:07</td>\n",
       "      <td>54</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>grebublin/coronavirus-propagation-visualizatio...</td>\n",
       "      <td>Coronavirus propagation visualization &amp; forecast.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mykola Maliarenko</td>\n",
       "      <td>2020-03-14 18:12:14</td>\n",
       "      <td>119</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>utkarshtomar736/odi-mens-cricket-match-data-20...</td>\n",
       "      <td>ODI Men's Cricket Match Data (2002-2023)</td>\n",
       "      <td>7MB</td>\n",
       "      <td>2023-09-25 15:31:05</td>\n",
       "      <td>1620</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>thykhuely/mercari-interactive-eda-topic-modelling</td>\n",
       "      <td>Mercari Interactive EDA + Topic Modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ThyKhueLy</td>\n",
       "      <td>2018-04-22 08:23:34</td>\n",
       "      <td>921</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>therval/poverty-rate-analysis-regression-and-pca</td>\n",
       "      <td>Poverty rate analysis / regression and PCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valentin Joly</td>\n",
       "      <td>2020-04-01 18:09:17</td>\n",
       "      <td>12</td>\n",
       "      <td>Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>sara88alaa/covid-19</td>\n",
       "      <td>covid_19</td>\n",
       "      <td>133MB</td>\n",
       "      <td>2023-04-06 21:23:28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "229                    hemil26/nft-collections-dataset   \n",
       "370  arjundas/simpleanalysis-for-kiva-its-time-for-...   \n",
       "44                          lakshyaag/india-trade-data   \n",
       "427                  ash316/eda-to-prediction-dietanic   \n",
       "467         inversion/get-started-with-mean-imputation   \n",
       "332  grebublin/coronavirus-propagation-visualizatio...   \n",
       "34   utkarshtomar736/odi-mens-cricket-match-data-20...   \n",
       "435  thykhuely/mercari-interactive-eda-topic-modelling   \n",
       "369   therval/poverty-rate-analysis-regression-and-pca   \n",
       "171                                sara88alaa/covid-19   \n",
       "\n",
       "                                                 title   size  \\\n",
       "229                                   NFT Collections     7KB   \n",
       "370   SimpleAnalysis for KIVA (Its time for Africa!!!)    NaN   \n",
       "44                                  India - Trade Data    3MB   \n",
       "427                        EDA To Prediction(DieTanic)    NaN   \n",
       "467                   Get Started with Mean Imputation    NaN   \n",
       "332  Coronavirus propagation visualization & forecast.    NaN   \n",
       "34            ODI Men's Cricket Match Data (2002-2023)    7MB   \n",
       "435          Mercari Interactive EDA + Topic Modelling    NaN   \n",
       "369        Poverty rate analysis / regression and PCA     NaN   \n",
       "171                                           covid_19  133MB   \n",
       "\n",
       "             lastUpdated downloadCount voteCount usabilityRating  \\\n",
       "229  2022-10-02 08:36:49          2667       129             1.0   \n",
       "370                  NaN           NaN       NaN             NaN   \n",
       "44   2022-11-02 07:31:00         25081       453       0.9705882   \n",
       "427                  NaN           NaN       NaN             NaN   \n",
       "467                  NaN           NaN       NaN             NaN   \n",
       "332                  NaN           NaN       NaN             NaN   \n",
       "34   2023-09-25 15:31:05          1620        35             1.0   \n",
       "435                  NaN           NaN       NaN             NaN   \n",
       "369                  NaN           NaN       NaN             NaN   \n",
       "171  2023-04-06 21:23:28             3         0          0.0625   \n",
       "\n",
       "                author          lastRunTime totalVotes      type  \n",
       "229                NaN                  NaN        NaN   Dataset  \n",
       "370                ADM  2018-05-12 05:57:27        170  Notebook  \n",
       "44                 NaN                  NaN        NaN   Dataset  \n",
       "427      Ashwini Swain  2018-03-08 17:55:32       2952  Notebook  \n",
       "467          inversion  2022-05-26 20:55:07         54  Notebook  \n",
       "332  Mykola Maliarenko  2020-03-14 18:12:14        119  Notebook  \n",
       "34                 NaN                  NaN        NaN   Dataset  \n",
       "435          ThyKhueLy  2018-04-22 08:23:34        921  Notebook  \n",
       "369      Valentin Joly  2020-04-01 18:09:17         12  Notebook  \n",
       "171                NaN                  NaN        NaN   Dataset  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Unido.sample(10)                     #Se muestran 10 resultados al azar del DataFrame unido final"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "finalized": {
   "timestamp": 1621297898005,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
