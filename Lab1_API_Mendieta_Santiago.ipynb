{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wgigj_IaZB6"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 30%;\">\n",
    "<img src=\"https://www.utpl.edu.ec/sites/default/files/archivos/marca%20UTPL%202018-02.png\", align=\"left\" width=\"280\" height=\"120\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 70%;\">\n",
    "<p style=\"margin: 0; padding-top: 32px; text-align:right; color:#003366; font-size:16px\"><u>Análisis de datos y visualización</u></p>\n",
    "<p style=\"margin: 0; text-align:right; color:#999999; font-size:17px\">Maestría en Inteligencia Artificial Aplicada</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Laboratorio 1: Extracción de datos mediante APIs\n",
    "\n",
    "La actividad práctico experimental tiene como objetivo validar su habilidad para usar APIs públicas para la extracción de datos.\n",
    "\n",
    "Desarrolle los ejercicios relacionados con la extracción y procesamiento de datos planteados en el notebook.\n",
    "\n",
    "Por cada ejercicio revise las indicaciones proporcionadas, para conseguir así el resultado que se espera.\n",
    "\n",
    "\n",
    "<b>Entregable de la actividad:</b>\n",
    "\n",
    "En la tarea habilitada, suba el notebook con la solución (en formato html o pdf). Antes de subir la solución verifique que consten todas las salidas que se esperan de cada ejercicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x97WwfMzdd95"
   },
   "source": [
    "## Paso 1: Configuración de acceso a API de Kaggle\n",
    "\n",
    "<b>Objetivo:</b> Conseguir un API token para comenzar a extraer los datos desde Kaggle.\n",
    "\n",
    "<b>Pasos:</b>\n",
    "\n",
    "1. Crear cuenta en Kaggle: https://www.kaggle.com/account/login\n",
    "2. Revisar la documentación de la API: https://www.kaggle.com/docs/api y seguir los pasos que constan en la sección <b>Authentication</b> para conseguir un API token. Según la documentación:\n",
    "\n",
    "&emsp;&emsp;&emsp;- <i>In order to use the Kaggle’s public API, you must first authenticate using an API token. Go to the 'Account' tab of your user profile and select 'Create New Token'. This will trigger the download of kaggle.json, a file containing your API credentials.</i>\n",
    "\n",
    "&emsp;&emsp;&emsp;Como resultado de esta acción guardar el archivo <b>kaggle.json</b>.\n",
    "\n",
    "4. Configurar credenciales de acceso: Dependiendo del entorno en el que trabaje hay dos opciones para hacer la configuración:\n",
    "\n",
    "&emsp;&emsp;4.1. Si es un entorno local, la documentación indica que hay que copiar el archivo kaggle.json en un directorio específico, según la siguiente instrucción.\n",
    "\n",
    "- <i>If you are using the Kaggle CLI tool, the tool will look for this token at ~/.kaggle/kaggle.json on Linux, OSX, and other UNIX-based operating systems, and at C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json on Windows. If the token is not there, an error will be raised. Hence, once you’ve downloaded the token, you should move it from your Downloads folder to this folder.</i>\n",
    "\n",
    "\n",
    "&emsp;&emsp;4.2. Si es en Google Colab: ejecutar los siguientes pasos cada vez que ingrese a Google Colab.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "Sh01J5JNaZB-"
   },
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from PIL import Image\n",
    "from IPython.core import display as ICD\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTnSnTnQaZB_"
   },
   "source": [
    "## Paso 2: Carga de palabras clave para realizar la búsqueda\n",
    "\n",
    "Objetivo: Cargar archivo de palabras clave y crear lista que sea procesable por la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "ULqyuCfsaZB_",
    "outputId": "f228475b-4be7-472c-b4b1-13b1a3f1196b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras clave:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binary classication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>missing values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword\n",
       "0    linear regression\n",
       "1  binary classication\n",
       "2        visualization\n",
       "3              poverty\n",
       "4             COVID 19\n",
       "5                  EDA\n",
       "6       missing values\n",
       "7             outliers"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar lista de palabras clave:\n",
    "kwDF = pd.read_csv('keywords.csv', header=None, names=['keyword']) # archivo sin encabezado\n",
    "\n",
    "print(\"Cantidad de palabras clave: \", kwDF.shape[0])\n",
    "\n",
    "kwDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK5c-IkXaZCB"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio: (1 pto) </b>\n",
    "\n",
    "<b>Objetivo:</b> Convertir los términos de varias palabras (separadas con espacio ' '), a términos cuyas palabras estén separadas con el signo '-'\n",
    "\n",
    "<b>Requisito:</b> La lista deberá llamarse  <i>kw</i>.\n",
    "\n",
    "<b>Salida esperada:</b> Objeto tipo lista que contenga los términos preprocesados.\n",
    "\n",
    "Por ejemplo, para el primer caso, en lugar de \"linear regression\" se debe generar el término \"linear_regression\"\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYKwU3QIaZCC",
    "outputId": "99d8abc5-83c0-41ce-cfee-3d9d6bbfc775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear_regression', 'binary_classication', 'visualization', 'poverty', 'COVID_19', 'EDA', 'missing_values', 'outliers']\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "#####################\n",
    "\n",
    "nfilas=len(kwDF)        #Numero de filas del dataframe con los Keywords.\n",
    "rango=range(0,nfilas)   #Rango desde cero hasta el numero de filas (0 a 8).\n",
    "kw=[]                   #Lista vacia para almacenar los palabras keywords con guiones.\n",
    "\n",
    "for fila in rango:                                       #Ciclo for para recorrer todas las filas del dataframe kwDF.\n",
    "    palabra=kwDF.loc[fila][\"keyword\"].replace(' ','_')   #Se reemplaza el espacio de cada keyword por un signo '_'.\n",
    "    kw.append(palabra)                                   #Se añaden los keywords a la lista kw.\n",
    "print(kw)                                                #Se imprime la lista kw para verificar los cambios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4JhWLx4aZCC"
   },
   "source": [
    "## Paso 2: Extracción de datos mediante API\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vb36fIxaZCD"
   },
   "source": [
    "### Paso 2.1. Extracción de datos desde Kaggle\n",
    "\n",
    "Consultar Documentación de la API: https://github.com/Kaggle/kaggle-api\n",
    "\n",
    "Luego de la revisión de la documentación, intentar comprender el procedimiento para obtener datasets y notebooks, con el objetivo de obtener las salidas que se esperan de cada ejercicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHH9mQ2IaZCF"
   },
   "source": [
    "### Preparar el request (importar libraries y definir parámetros generales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "BGFsgdhLaZCF"
   },
   "outputs": [],
   "source": [
    "import requests, json, time, random\n",
    "# importar libreria kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "0pHufYNraZCG"
   },
   "outputs": [],
   "source": [
    "# Llamar a la api key de kaggle instalada en el entorno seleccionado.\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYTUuiDRaZCG"
   },
   "source": [
    "Aunque la documentación de la API explica el proceso de consumo de datos, a continuación se presenta un ejemplo de extracción de metadatos de dataset. Observe los metadatos que devuelve la API y pruebe cómo obtendría los metadatos de notebooks.\n",
    "\n",
    "\n",
    "A partir del ejemplo planteado, desarrolle los ejercicios que continuan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBsjskuSaZCG",
    "outputId": "5355f1ba-f977-4a2c-a3d6-40fa6c3bfc87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,size,lastUpdated,downloadCount,voteCount,usabilityRating',\n",
       " 'aml0ali2000/linear-regression,Linear_regression,1KB,2023-12-04 14:34:14,7,2,0.3529412',\n",
       " 'kasiviswanath00/linear-regression,linear_regression,378B,2022-05-25 12:08:15,15,2,0.1764706',\n",
       " 'drakedyban/mediumlinear-regression,Medium-Linear_Regression,5KB,2021-02-28 22:37:25,19,1,0.4375',\n",
       " 'sangitamule/linear-regressionproject,/Linear_Regression-Project,40KB,2022-02-03 06:41:39,14,2,0.29411766',\n",
       " 'krishnamohanmaurya/linear-regression,Linear_Regression,5KB,2023-02-27 14:38:50,7,2,0.1764706']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso de la API:\n",
    "\n",
    "# Extracción de datasets:\n",
    "tema = kw[0]  # toma el primer término o palabra que se cargó desde el csv\n",
    "page = 1  # obtener los datos de la primera página, se puede cambiar iterativamente este valor para recuperar más resultados\n",
    "\n",
    "#Llamada para obtener metadatos de datasets de un tema en particular y de una página específica.\n",
    "lista = !kaggle datasets list -s $tema --csv -p $page  \n",
    "results=[l for l in lista if len(l)]       #Se filtran los resultados para que no se incluyan en la lista elementos vacios.\n",
    "results[:6]                                # Presentar los 5 primeros resutados en forma de lista, incluyendo el resultado para las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ref                       title  size  \\\n",
       "1         aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2     kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3    drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4  sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5  krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "\n",
       "           lastUpdated downloadCount voteCount usabilityRating  \n",
       "1  2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2  2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3  2021-02-28 22:37:25            19         1          0.4375  \n",
       "4  2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5  2023-02-27 14:38:50             7         2       0.1764706  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos adicionales del ejemplo para mostrar los 5 primeros resultados en un DataFrame\n",
    "results2=[]             #Nueva lista vacía\n",
    "d=len(results)          #Numero de elementos de la lista de resultados de datasets\n",
    "r=range(0,d)            #Rango para la iteracion\n",
    "for i in r:                                #Ciclo repetitivo para recorrer toda la lista results\n",
    "    results_split=results[i].split(',')    #Se separan los elementos de cada posicion de la lista results\n",
    "    results2.append(results_split)         #Se añaden cada lista de elementos separados en la lista results2\n",
    "results_DF=pd.DataFrame(results2, columns=results2[0])     #Se transforma en dataframe la lista results2 (lista de listas)\n",
    "results_DF[1:6]                            #Se muestran los primeros 5 resultados, sin contar el resultado para las columnas                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_JA8KqXaZCH"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 2 (1.75 ptos): Obtención de metadatos de datasets.</b>\n",
    "\n",
    "<b>Objetivo:</b> Mediante un proceso repetitivo, recuperar los <b>datasets</b> que estén relacionados con las palabras clave contenidas en la lista de keywords previamente creada (<i>kw</i>).\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer toda la lista de palabras clave para obtener todos los datasets que consten en las primeras 3 páginas (por cada palabra clave).\n",
    "- Acumular los resultados en una lista que se denomine <i> datasets </i>\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros datasets recuperados.\n",
    "\n",
    "En el ejemplo, proporcionado arriba, puede ver una muestra de los resultados esperados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "CknVrp43aZCH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,size,lastUpdated,downloadCount,voteCount,usabilityRating',\n",
       " 'aml0ali2000/linear-regression,Linear_regression,1KB,2023-12-04 14:34:14,7,2,0.3529412',\n",
       " 'kasiviswanath00/linear-regression,linear_regression,378B,2022-05-25 12:08:15,15,2,0.1764706',\n",
       " 'drakedyban/mediumlinear-regression,Medium-Linear_Regression,5KB,2021-02-28 22:37:25,19,1,0.4375',\n",
       " 'sangitamule/linear-regressionproject,/Linear_Regression-Project,40KB,2022-02-03 06:41:39,14,2,0.29411766',\n",
       " 'krishnamohanmaurya/linear-regression,Linear_Regression,5KB,2023-02-27 14:38:50,7,2,0.1764706',\n",
       " 'iflahgulzar/linear-regression,linear_regression,8KB,2023-02-26 16:36:10,9,1,0.1764706',\n",
       " 'viveckrajasekar/linear-regression,Linear_Regression,13KB,2019-06-28 14:24:45,61,1,0.11764706',\n",
       " 'pankajsinghardh/linear-regression,linear_regression,213B,2023-08-27 05:40:10,6,0,0.3125',\n",
       " 'nurmannaz/linear-regression,linear_regression,220B,2022-03-01 21:17:06,14,0,0.1764706']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "# Extracción de datasets:\n",
    "datasets=[]                     #Lista vacía para guardar todos los datasets\n",
    "rango2=range(1,4)               #Rango para el numero de paginas: 1,2 y 3.\n",
    "for fila in rango:                                 #Ciclo repetitivo para recorrer todas las keywords de la lista kw\n",
    "    for pagina in rango2:                          #Ciclo repetitivo para recorrer las paginas\n",
    "        tema = kw[fila]                            #Se toma cada keyword y se le asigna a la variable tema\n",
    "        page = pagina                              #Cada pagina se asigna a la variable page      \n",
    "        #Llamada para obtener metadatos de datasets de un tema y de una página específica. Los resultados se guardan en una lista.\n",
    "        lista = !kaggle datasets list -s $tema --csv -p $page \n",
    "        results=[l for l in lista if len(l) and l!='No datasets found']  #Se filtran los resultados para que no se incluyan elementos vacios.      \n",
    "        datasets.extend(results)                   #Los resultados de cada iteración se acumulan en la lista llamada datasets\n",
    "datasets[:10]                                      #Se presentan los primeros 10 resutados de la lista datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iflahgulzar/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2023-02-26 16:36:10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viveckrajasekar/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2019-06-28 14:24:45</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nurmannaz/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>220B</td>\n",
       "      <td>2022-03-01 21:17:06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epsitabose/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2022-02-09 11:47:13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ref                       title  size  \\\n",
       "1          aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2      kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3     drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4   sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5   krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "6          iflahgulzar/linear-regression           linear_regression   8KB   \n",
       "7      viveckrajasekar/linear-regression           Linear_Regression  13KB   \n",
       "8      pankajsinghardh/linear-regression           linear_regression  213B   \n",
       "9            nurmannaz/linear-regression           linear_regression  220B   \n",
       "10          epsitabose/linear-regression           linear_regression   2MB   \n",
       "\n",
       "            lastUpdated downloadCount voteCount usabilityRating  \n",
       "1   2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2   2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3   2021-02-28 22:37:25            19         1          0.4375  \n",
       "4   2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5   2023-02-27 14:38:50             7         2       0.1764706  \n",
       "6   2023-02-26 16:36:10             9         1       0.1764706  \n",
       "7   2019-06-28 14:24:45            61         1      0.11764706  \n",
       "8   2023-08-27 05:40:10             6         0          0.3125  \n",
       "9   2022-03-01 21:17:06            14         0       0.1764706  \n",
       "10  2022-02-09 11:47:13             6         1             0.0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos para mostrar los 10 primeros resultados de la lista datasets en un DataFrame\n",
    "datasets2=[]            #Nueva lista vacía\n",
    "d=len(datasets)       #Numero de elementos de la lista datasets\n",
    "r=range(0,d)         #Rango para la iteracion\n",
    "for i in r:                                  #Ciclo repetitivo para recorrer toda la lista datasets\n",
    "    datasets_split=datasets[i].split(',',6)  #Se separan los elementos de cada posicion de la lista datasets\n",
    "    datasets2.append(datasets_split)         #Se añade cada lista de elementos separados en la lista datasets2\n",
    "datasets_DF=pd.DataFrame(datasets2, columns=datasets2[0])  #Se transforma en dataframe la lista datasets2 (lista de listas)\n",
    "datasets_DF[1:11]                            #Se muestran los primeros 10 resultados de los datasets, sin incluir los resultados para las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ajiteshmahalingam/covid-19</td>\n",
       "      <td>Covid_19</td>\n",
       "      <td>3MB</td>\n",
       "      <td>2021-01-27 08:59:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>raviiloveyou/covid-19</td>\n",
       "      <td>covid_19</td>\n",
       "      <td>14MB</td>\n",
       "      <td>2023-10-12 07:11:08</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>sandeshbhat/satellite-images-to-predict-povert...</td>\n",
       "      <td>Satellite Images to predict poverty</td>\n",
       "      <td>5GB</td>\n",
       "      <td>2021-01-11 11:34:27</td>\n",
       "      <td>548</td>\n",
       "      <td>21</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>meetnagadia/share-price-of-top-electric-car-co...</td>\n",
       "      <td>Share price of Top Electric Car Company</td>\n",
       "      <td>211KB</td>\n",
       "      <td>2021-08-24 09:23:30</td>\n",
       "      <td>942</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>lingutlaaswini/covid-19-india-dataset</td>\n",
       "      <td>Covid_19_india dataset</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2020-06-26 12:21:57</td>\n",
       "      <td>456</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ananyagr/covid-19</td>\n",
       "      <td>covid_19</td>\n",
       "      <td>15MB</td>\n",
       "      <td>2022-01-24 15:09:01</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>azeez01/multilinear-regression</td>\n",
       "      <td>Multi-Linear_regression</td>\n",
       "      <td>599B</td>\n",
       "      <td>2022-09-06 18:39:58</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ref</td>\n",
       "      <td>title</td>\n",
       "      <td>size</td>\n",
       "      <td>lastUpdated</td>\n",
       "      <td>downloadCount</td>\n",
       "      <td>voteCount</td>\n",
       "      <td>usabilityRating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ddosad/customer-behaviour-tourism-portal</td>\n",
       "      <td>Tourism Page Engagement</td>\n",
       "      <td>235KB</td>\n",
       "      <td>2023-11-13 15:17:08</td>\n",
       "      <td>1448</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yashrana24/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>24KB</td>\n",
       "      <td>2023-01-29 13:09:37</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "157                         ajiteshmahalingam/covid-19   \n",
       "139                              raviiloveyou/covid-19   \n",
       "90   sandeshbhat/satellite-images-to-predict-povert...   \n",
       "243  meetnagadia/share-price-of-top-electric-car-co...   \n",
       "137              lingutlaaswini/covid-19-india-dataset   \n",
       "169                                  ananyagr/covid-19   \n",
       "11                      azeez01/multilinear-regression   \n",
       "93                                                 ref   \n",
       "220           ddosad/customer-behaviour-tourism-portal   \n",
       "13                        yashrana24/linear-regression   \n",
       "\n",
       "                                        title   size          lastUpdated  \\\n",
       "157                                  Covid_19    3MB  2021-01-27 08:59:00   \n",
       "139                                  covid_19   14MB  2023-10-12 07:11:08   \n",
       "90        Satellite Images to predict poverty    5GB  2021-01-11 11:34:27   \n",
       "243  Share price of Top Electric Car Company   211KB  2021-08-24 09:23:30   \n",
       "137                    Covid_19_india dataset    1MB  2020-06-26 12:21:57   \n",
       "169                                  covid_19   15MB  2022-01-24 15:09:01   \n",
       "11                    Multi-Linear_regression   599B  2022-09-06 18:39:58   \n",
       "93                                      title   size          lastUpdated   \n",
       "220                   Tourism Page Engagement  235KB  2023-11-13 15:17:08   \n",
       "13                          linear_regression   24KB  2023-01-29 13:09:37   \n",
       "\n",
       "     downloadCount  voteCount  usabilityRating  \n",
       "157              8          1       0.11764706  \n",
       "139              4          3       0.23529412  \n",
       "90             548         21           0.8125  \n",
       "243            942         30           0.9375  \n",
       "137            456          8       0.29411766  \n",
       "169              8          1              0.0  \n",
       "11              27          1       0.11764706  \n",
       "93   downloadCount  voteCount  usabilityRating  \n",
       "220           1448         60              1.0  \n",
       "13               5          0              0.0  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_DF.sample(10)                       #Se muestran 10 resultados al azar de los datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvSrdH36aZCI"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 3 (1.75 puntos): Limpieza de metadatos de datasets.</b>\n",
    "\n",
    "<b>Objetivo:</b> Limpiar los metadatos de datasets de tal manera que no hayan elementos duplicados, ni hayan datos con valores inesperados.\n",
    "\n",
    "<b>Contexto:</b> Algunos datasets pueden repetirse en diferentes llamada, esto puede ocurrir cuando un dataset está asociado a varias palabras clave que constan en el archivo de keywords. Por ejemplo, si un dataset tiene dos palabras clave como: linear regression y COVID-19, entonces, va a salir en ambos resultados.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer la lista de resultados <i> datasets </i> y dejar solo resultados únicos de datasets.\n",
    "- Explorar los resultados obtenidos para verificar que los datos no contienen caracteres o elementos extraños.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros datasets únicos que han sido procesados.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "CXRRB26caZCI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con valores nulos por columnas:\n",
      "ref                0\n",
      "title              3\n",
      "size               3\n",
      "lastUpdated        3\n",
      "downloadCount      3\n",
      "voteCount          3\n",
      "usabilityRating    3\n",
      "dtype: int64\n",
      "\n",
      "DataFrame con valores nulos por filas:\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "      ..\n",
      "283    0\n",
      "284    0\n",
      "285    0\n",
      "286    0\n",
      "287    6\n",
      "Length: 287, dtype: int64\n",
      "\n",
      "DataFrame solamente con las filas nulas:\n",
      "48     6\n",
      "114    6\n",
      "287    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "#Para la solucion se decide trabajar con los resultados obtenidos de los datasets en formato DataFrame\n",
    "\n",
    "#a.) Eliminación de los resultados duplicados del Dataframe\n",
    "datasets_DF_p=datasets_DF.drop_duplicates()                      #Se utiliza drop_duplicates() para eliminar las filas duplicadas\n",
    "datasets_DF_pp=datasets_DF_p.drop([0],axis=0)                    #Se elimina la primera fila que corresponde con los nombres de las columnas.\n",
    "datasets_DF_pp.index=range(1,len(datasets_DF_pp)+1)              #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_inicial=len(datasets_DF)                               #Se utiliza len para medir el tamaño del dataset sin procesar\n",
    "dimension_sin_duplicados=len(datasets_DF_pp)                     #Se utiliza len para medir el tamaño del dataset preprocesado\n",
    "cantidad_duplicados=dimension_inicial-dimension_sin_duplicados   #Se calcula la cantidad de elementos duplicados\n",
    "\n",
    "#b.) Verificar si hay valores inesperados\n",
    "valores_null_columnas=datasets_DF_pp.isnull().sum()              #Se guarda en un DataFrame el numero de valores nulos por columnas\n",
    "valores_null_filas=(datasets_DF_pp.isnull().sum(axis=1))         #Se guarda en un DataFrame el numero de valores nulos por filas\n",
    "\n",
    "filas_nulas=[]                                                   #Lista vacia para almacenar las filas nulas                   \n",
    "for j in range(1,len(valores_null_filas)+1):                     #Ciclo repetitivo para recorrer el DataFrame con el numero de valores nulos por filas\n",
    "    if valores_null_filas[j]!=0:                                 #Cuando el valor de la fila es distinto de cero se añade en la lista \n",
    "        filas_nulas.append(j)\n",
    "valores_null_filas_filtradas=valores_null_filas[filas_nulas]     #Dataframe solamente con las filas nulas\n",
    "\n",
    "print(\"DataFrame con valores nulos por columnas:\")               #Se imprime el DataFrame con el numero de valores nulos por columnas\n",
    "print(valores_null_columnas)\n",
    "print(\"\\nDataFrame con valores nulos por filas:\")                #Se imprime el DataFrame con el numero de valores nulos por filas\n",
    "print(valores_null_filas)\n",
    "print(\"\\nDataFrame solamente con las filas nulas:\")              #Se imprimen el Dataframe anterior solamente con las filas nulas\n",
    "print(valores_null_filas_filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De  acuerdo al analisis anterior existen 3 filas con valores nulos. Las cuales tienen vacias todas sus columnas a excepcion de la primera\n",
    "#Se decide eliminar estas filas \n",
    "\n",
    "datasets_DF_prep=datasets_DF_pp.drop(filas_nulas,axis=0)         #Se eliminan las filas con valores nulos\n",
    "datasets_DF_prep.index=range(1,len(datasets_DF_prep)+1)          #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_final=len(datasets_DF_prep)                            #Se utiliza len para medir el tamaño del dataset preprocesado final\n",
    "filas_eliminadas_vacias=len(filas_nulas)                         #Se utiliza len para medir el tamaño de filas eliminadas\n",
    "cantidad_filas_eliminadas=dimension_inicial-dimension_final      #Se calcula la cantidad de elementos eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension inicial del Dataframe: 307\n",
      "Dimension del Dataframe sin elementos duplicados: 287\n",
      "Cantidad de filas duplicadas: 20\n",
      "Dimension del DataFrame con datos únicos preprocesados: 284\n",
      "Cantidad de filas eliminadas vacias: 3\n",
      "Cantidad total de filas eliminadas: 23\n",
      "\n",
      "Dataframe con datos únicos preprocesados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iflahgulzar/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2023-02-26 16:36:10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viveckrajasekar/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2019-06-28 14:24:45</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nurmannaz/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>220B</td>\n",
       "      <td>2022-03-01 21:17:06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epsitabose/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2022-02-09 11:47:13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ref                       title  size  \\\n",
       "1          aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2      kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3     drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4   sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5   krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "6          iflahgulzar/linear-regression           linear_regression   8KB   \n",
       "7      viveckrajasekar/linear-regression           Linear_Regression  13KB   \n",
       "8      pankajsinghardh/linear-regression           linear_regression  213B   \n",
       "9            nurmannaz/linear-regression           linear_regression  220B   \n",
       "10          epsitabose/linear-regression           linear_regression   2MB   \n",
       "\n",
       "            lastUpdated downloadCount voteCount usabilityRating  \n",
       "1   2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2   2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3   2021-02-28 22:37:25            19         1          0.4375  \n",
       "4   2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5   2023-02-27 14:38:50             7         2       0.1764706  \n",
       "6   2023-02-26 16:36:10             9         1       0.1764706  \n",
       "7   2019-06-28 14:24:45            61         1      0.11764706  \n",
       "8   2023-08-27 05:40:10             6         0          0.3125  \n",
       "9   2022-03-01 21:17:06            14         0       0.1764706  \n",
       "10  2022-02-09 11:47:13             6         1             0.0  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c.) Impresion de resultados\n",
    "print(\"Dimension inicial del Dataframe:\",dimension_inicial)      #Se imprime el tamaño del dataset sin procesar\n",
    "print(\"Dimension del Dataframe sin elementos duplicados:\",dimension_sin_duplicados)   #Se imprime el tamaño del dataset preprocesado\n",
    "print(\"Cantidad de filas duplicadas:\",cantidad_duplicados)   #Se imprime la cantidad de elementos duplicados\n",
    "print(\"Dimension del DataFrame con datos únicos preprocesados:\",dimension_final)      #Se imprime la cantidad de elementos del DataFrame preprocesado\n",
    "print(\"Cantidad de filas eliminadas vacias:\",filas_eliminadas_vacias)   #Se imprime la cantidad de filas_eliminadas\n",
    "print(\"Cantidad total de filas eliminadas:\",cantidad_filas_eliminadas)  #Se imprime la cantidad de filas_eliminadas\n",
    "print(\"\\nDataframe con datos únicos preprocesados:\")                           \n",
    "datasets_DF_prep[:10]                                            #Se imprimen los 10 primeros resultados del DataFrame preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>datatattle/guns-incident-data</td>\n",
       "      <td>Guns incident data</td>\n",
       "      <td>937KB</td>\n",
       "      <td>2020-09-07 15:05:09</td>\n",
       "      <td>681</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>codebreaker619/boston-hubway-data-visualizatio...</td>\n",
       "      <td>Boston Hubway Data Visualization Challenge Dat...</td>\n",
       "      <td>29MB</td>\n",
       "      <td>2021-01-10 19:00:04</td>\n",
       "      <td>639</td>\n",
       "      <td>23</td>\n",
       "      <td>0.9411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>mariotormo/complete-pokemon-dataset-updated-09...</td>\n",
       "      <td>Complete Pokemon Dataset (Updated 16.04.21)</td>\n",
       "      <td>195KB</td>\n",
       "      <td>2021-04-16 06:32:50</td>\n",
       "      <td>9909</td>\n",
       "      <td>171</td>\n",
       "      <td>0.9705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>gokulrajkmv/indian-statewise-data-from-rbi</td>\n",
       "      <td>India's state-wise data</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2020-07-14 07:27:42</td>\n",
       "      <td>3120</td>\n",
       "      <td>29</td>\n",
       "      <td>0.85294116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>vishweshsalodkar/customer-feedback-dataset</td>\n",
       "      <td>Customer Feedback Dataset</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2023-07-02 10:07:10</td>\n",
       "      <td>3060</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>statchaitya/a-few-poverty-indicators-for-phili...</td>\n",
       "      <td>A few poverty indicators for philippines by re...</td>\n",
       "      <td>12MB</td>\n",
       "      <td>2018-04-30 03:01:02</td>\n",
       "      <td>585</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>danofer/wb-poverty</td>\n",
       "      <td>World Bank Poverty Report</td>\n",
       "      <td>107KB</td>\n",
       "      <td>2018-02-28 10:59:53</td>\n",
       "      <td>1524</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>johnnyyiu/predicting-poverty</td>\n",
       "      <td>Poverty Probability Index &amp; Economic Indicators</td>\n",
       "      <td>644KB</td>\n",
       "      <td>2019-07-22 06:44:34</td>\n",
       "      <td>2128</td>\n",
       "      <td>22</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>eishkaran/world-poverty-data</td>\n",
       "      <td>World Poverty Data</td>\n",
       "      <td>4MB</td>\n",
       "      <td>2023-10-14 21:22:53</td>\n",
       "      <td>371</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>asaniczka/us-cost-of-living-dataset-3171-counties</td>\n",
       "      <td>US Cost of Living Dataset (1877 Counties)</td>\n",
       "      <td>1MB</td>\n",
       "      <td>2024-02-17 14:16:32</td>\n",
       "      <td>2271</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "191                      datatattle/guns-incident-data   \n",
       "38   codebreaker619/boston-hubway-data-visualizatio...   \n",
       "224  mariotormo/complete-pokemon-dataset-updated-09...   \n",
       "102         gokulrajkmv/indian-statewise-data-from-rbi   \n",
       "65          vishweshsalodkar/customer-feedback-dataset   \n",
       "106  statchaitya/a-few-poverty-indicators-for-phili...   \n",
       "79                                  danofer/wb-poverty   \n",
       "77                        johnnyyiu/predicting-poverty   \n",
       "83                        eishkaran/world-poverty-data   \n",
       "97   asaniczka/us-cost-of-living-dataset-3171-counties   \n",
       "\n",
       "                                                 title   size  \\\n",
       "191                                 Guns incident data  937KB   \n",
       "38   Boston Hubway Data Visualization Challenge Dat...   29MB   \n",
       "224        Complete Pokemon Dataset (Updated 16.04.21)  195KB   \n",
       "102                            India's state-wise data    2KB   \n",
       "65                           Customer Feedback Dataset    4KB   \n",
       "106  A few poverty indicators for philippines by re...   12MB   \n",
       "79                           World Bank Poverty Report  107KB   \n",
       "77     Poverty Probability Index & Economic Indicators  644KB   \n",
       "83                                  World Poverty Data    4MB   \n",
       "97           US Cost of Living Dataset (1877 Counties)    1MB   \n",
       "\n",
       "             lastUpdated downloadCount voteCount usabilityRating  \n",
       "191  2020-09-07 15:05:09           681        19             1.0  \n",
       "38   2021-01-10 19:00:04           639        23       0.9411765  \n",
       "224  2021-04-16 06:32:50          9909       171       0.9705882  \n",
       "102  2020-07-14 07:27:42          3120        29      0.85294116  \n",
       "65   2023-07-02 10:07:10          3060        53             1.0  \n",
       "106  2018-04-30 03:01:02           585         9       0.7058824  \n",
       "79   2018-02-28 10:59:53          1524        34       0.9117647  \n",
       "77   2019-07-22 06:44:34          2128        22       0.8235294  \n",
       "83   2023-10-14 21:22:53           371        22       0.7058824  \n",
       "97   2024-02-17 14:16:32          2271       104             1.0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_DF_prep.sample(10)                                      #Se muestran 10 resultados al azar del dataset preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6ufgdIiaZCK"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 4 (1.75 puntos): Obtención de metadatos de notebooks.</b>\n",
    "\n",
    "<b>Objetivo:</b> Mediante un proceso repetitivo, recuperar los <b>notebooks</b> que estén relacionados con las palabras clave contenidas en la lista de keywords previamente creada (<i>kw</i>). Este ejercicio es similar anterior, pero, la idea es centrarse en los notebooks.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer toda la lista de palabras clave para obtener todos los notebooks que consten en las primeras 3 páginas (por cada palabra clave).\n",
    "- Acumular los resultados en una lista que se denomine <i> notebooks </i>\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros notebooks recuperados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "J268BLRgaZCK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ref,title,author,lastRunTime,totalVotes',\n",
       " 'hakmatkhan/linear-regression,Linear_regression,Hakmat khan,2023-01-05 15:30:05,2',\n",
       " 'sanket82/linear-regression,Linear_Regression,Sanket Adamapure,2022-01-30 17:04:53,2',\n",
       " 'nkitgupta/feature-engineering-and-feature-selection,Feature Engineering and Feature Selection,Ankit Gupta,2022-04-28 13:34:32,172',\n",
       " 'baljeeta/linear-regression-medical-insurance,Linear_regression(Medical_Insurance),Baljeeta,2024-03-22 10:51:07,6',\n",
       " 'meltemsprtl/linear-regression,linear_regression,Meltem SUPURTULU,2022-02-09 07:51:36,3',\n",
       " 'abdul3344/linear-regression,Linear_Regression,Abdul3344,2022-11-07 17:17:21,3',\n",
       " 'mustiztemiz/linear-regression-house-rice-prediction,Linear_Regression _House_rice_prediction,mustafa öztemiz,2021-11-12 17:16:49,5',\n",
       " 'rashmiek99/head-size-vs-brain-weight,Head Size Vs Brain Weight,Rashmi,2019-08-01 01:03:35,24',\n",
       " 'aiyoweidtt/linear-regression-decision-tree-random-forest,Linear_Regression/Decision_Tree/Random_Forest,Aiyowei,2019-08-22 08:50:50,3']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "# Extracción de notebooks:\n",
    "notebooks=[]                    #Lista vacía para guardar todos los notebooks\n",
    "num_filas=len(kw)               #Numero de filas de kw\n",
    "rango=range(0,num_filas)        #Rango para el numero de filas de lista kw\n",
    "rango2=range(1,4)               #Rango para el numero de paginas: 1,2 y 3.\n",
    "for fila in rango:                                 #Ciclo repetitivo para recorrer todas las keywords de la lista kw\n",
    "    for pagina in rango2:                          #Ciclo repetitivo para recorrer las paginas\n",
    "        tema = kw[fila]                            #Se toma cada keyword y se le asigna a la variable tema\n",
    "        page = pagina                              #Cada pagina se asigna a la variable page      \n",
    "        #Llamada para obtener metadatos de notebooks de un tema y de una página específica. Los resultados se guardan en una lista.\n",
    "        lista = !kaggle kernels list -s $tema --csv -p $page \n",
    "        results=[l for l in lista if len(l) and l!='Not found']   #Se filtran los resultados para que no se incluyan elementos vacios.      \n",
    "        notebooks.extend(results)                  #Los resultados de cada iteración se acumulan en la lista llamada notebooks\n",
    "a=0                                                #Se declara la variable 'a' para el bucle while\n",
    "while a==0 or a==1:                                #Bucle while para que se ejecute dos veces\n",
    "    notebooks.remove(notebooks[0])                 #Se elimina el primer y segundo termino de la lista obtenida, dado que en la llamada...\n",
    "    a+=1                                           #...corresponden con los titulos de las columnas (ref,title,author,lastRunTime,totalVotes)\n",
    "notebooks[:10]                                     #Se presentan los primeros 10 resutados de la lista notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hakmatkhan/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>Hakmat khan</td>\n",
       "      <td>2023-01-05 15:30:05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanket82/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Sanket Adamapure</td>\n",
       "      <td>2022-01-30 17:04:53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nkitgupta/feature-engineering-and-feature-sele...</td>\n",
       "      <td>Feature Engineering and Feature Selection</td>\n",
       "      <td>Ankit Gupta</td>\n",
       "      <td>2022-04-28 13:34:32</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baljeeta/linear-regression-medical-insurance</td>\n",
       "      <td>Linear_regression(Medical_Insurance)</td>\n",
       "      <td>Baljeeta</td>\n",
       "      <td>2024-03-22 10:51:07</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meltemsprtl/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Meltem SUPURTULU</td>\n",
       "      <td>2022-02-09 07:51:36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abdul3344/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Abdul3344</td>\n",
       "      <td>2022-11-07 17:17:21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mustiztemiz/linear-regression-house-rice-predi...</td>\n",
       "      <td>Linear_Regression _House_rice_prediction</td>\n",
       "      <td>mustafa öztemiz</td>\n",
       "      <td>2021-11-12 17:16:49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rashmiek99/head-size-vs-brain-weight</td>\n",
       "      <td>Head Size Vs Brain Weight</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>2019-08-01 01:03:35</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aiyoweidtt/linear-regression-decision-tree-ran...</td>\n",
       "      <td>Linear_Regression/Decision_Tree/Random_Forest</td>\n",
       "      <td>Aiyowei</td>\n",
       "      <td>2019-08-22 08:50:50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ajcostarino/ingv-volcanic-eruption-prediction-...</td>\n",
       "      <td>INGV Volcanic Eruption Prediction - LGBM Base...</td>\n",
       "      <td>Adam James</td>\n",
       "      <td>2020-12-15 21:35:13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ref  \\\n",
       "1                        hakmatkhan/linear-regression   \n",
       "2                          sanket82/linear-regression   \n",
       "3   nkitgupta/feature-engineering-and-feature-sele...   \n",
       "4        baljeeta/linear-regression-medical-insurance   \n",
       "5                       meltemsprtl/linear-regression   \n",
       "6                         abdul3344/linear-regression   \n",
       "7   mustiztemiz/linear-regression-house-rice-predi...   \n",
       "8                rashmiek99/head-size-vs-brain-weight   \n",
       "9   aiyoweidtt/linear-regression-decision-tree-ran...   \n",
       "10  ajcostarino/ingv-volcanic-eruption-prediction-...   \n",
       "\n",
       "                                                title            author  \\\n",
       "1                                   Linear_regression       Hakmat khan   \n",
       "2                                   Linear_Regression  Sanket Adamapure   \n",
       "3           Feature Engineering and Feature Selection       Ankit Gupta   \n",
       "4                Linear_regression(Medical_Insurance)          Baljeeta   \n",
       "5                                   linear_regression  Meltem SUPURTULU   \n",
       "6                                   Linear_Regression         Abdul3344   \n",
       "7            Linear_Regression _House_rice_prediction   mustafa öztemiz   \n",
       "8                           Head Size Vs Brain Weight            Rashmi   \n",
       "9       Linear_Regression/Decision_Tree/Random_Forest           Aiyowei   \n",
       "10   INGV Volcanic Eruption Prediction - LGBM Base...        Adam James   \n",
       "\n",
       "            lastRunTime totalVotes  \n",
       "1   2023-01-05 15:30:05          2  \n",
       "2   2022-01-30 17:04:53          2  \n",
       "3   2022-04-28 13:34:32        172  \n",
       "4   2024-03-22 10:51:07          6  \n",
       "5   2022-02-09 07:51:36          3  \n",
       "6   2022-11-07 17:17:21          3  \n",
       "7   2021-11-12 17:16:49          5  \n",
       "8   2019-08-01 01:03:35         24  \n",
       "9   2019-08-22 08:50:50          3  \n",
       "10  2020-12-15 21:35:13         47  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasos para mostrar los 10 primeros resultados de la lista notebooks en un DataFrame\n",
    "notebooks2=[]         #Nueva lista vacía\n",
    "d=len(notebooks)      #Numero de elementos de la lista notebooks\n",
    "r=range(0,d)          #Rango para la iteracion\n",
    "for i in r:                                    #Ciclo repetitivo para recorrer toda la lista notebooks\n",
    "    notebooks_split=notebooks[i].split(',',4)  #Se separan los elementos de cada posicion de la lista notebooks\n",
    "    notebooks2.append(notebooks_split)         #Se añade cada lista de elementos separados en la lista notebooks2\n",
    "notebooks_DF=pd.DataFrame(notebooks2, columns=notebooks2[0])  #Se transforma en dataframe la lista notebooks2 (lista de listas)\n",
    "notebooks_DF[1:11]                             #Se muestran los primeros 10 resultados de los notebooks, sin incluir los resultados para las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>andresionek/geospatial-analysis-of-brazilian-e...</td>\n",
       "      <td>Geospatial Analysis of Brazilian E-Commerce</td>\n",
       "      <td>Andre Sionek</td>\n",
       "      <td>2018-11-29 13:42:16</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>nicapotato/costa-rican-poverty-distributions-a...</td>\n",
       "      <td>Costa Rican Poverty - Distributions and Corr</td>\n",
       "      <td>nicapotato</td>\n",
       "      <td>2018-07-29 10:34:20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rahul1394/weight-height-prediction-linear-regr...</td>\n",
       "      <td>Weight-Height_Prediction(Linear_Regression)</td>\n",
       "      <td>rahul</td>\n",
       "      <td>2019-08-27 15:55:56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanket82/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>Sanket Adamapure</td>\n",
       "      <td>2022-01-30 17:04:53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>joshuaswords/awesome-hr-data-visualization-pre...</td>\n",
       "      <td>Awesome HR Data Visualization &amp; Prediction</td>\n",
       "      <td>Josh</td>\n",
       "      <td>2021-04-27 13:20:41</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>xvivancos/data-breaches-tableau-visualization</td>\n",
       "      <td>Data Breaches Tableau Visualization</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>2023-01-25 13:38:49</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>dgawlik/house-prices-eda</td>\n",
       "      <td>House Prices EDA</td>\n",
       "      <td>Dominik Gawlik</td>\n",
       "      <td>2017-02-20 10:51:47</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>cdeotte/keras-unet-with-eda</td>\n",
       "      <td>Keras UNET with EDA</td>\n",
       "      <td>Chris Deotte</td>\n",
       "      <td>2019-08-10 10:55:52</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>rsesha/covid-19-image-classification-deep-auto...</td>\n",
       "      <td>COVID_19_Image_Classification_Deep_AutoViML</td>\n",
       "      <td>RSESHA</td>\n",
       "      <td>2021-08-08 22:46:10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>aikhmelnytskyy/public-krni-pdi-with-two-additi...</td>\n",
       "      <td>public_krni_pdi_:( with two additional models</td>\n",
       "      <td>Andrij</td>\n",
       "      <td>2023-07-02 19:30:24</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "121  andresionek/geospatial-analysis-of-brazilian-e...   \n",
       "109  nicapotato/costa-rican-poverty-distributions-a...   \n",
       "11   rahul1394/weight-height-prediction-linear-regr...   \n",
       "2                           sanket82/linear-regression   \n",
       "65   joshuaswords/awesome-hr-data-visualization-pre...   \n",
       "61       xvivancos/data-breaches-tableau-visualization   \n",
       "165                           dgawlik/house-prices-eda   \n",
       "181                        cdeotte/keras-unet-with-eda   \n",
       "139  rsesha/covid-19-image-classification-deep-auto...   \n",
       "203  aikhmelnytskyy/public-krni-pdi-with-two-additi...   \n",
       "\n",
       "                                             title            author  \\\n",
       "121    Geospatial Analysis of Brazilian E-Commerce      Andre Sionek   \n",
       "109   Costa Rican Poverty - Distributions and Corr        nicapotato   \n",
       "11     Weight-Height_Prediction(Linear_Regression)             rahul   \n",
       "2                                Linear_Regression  Sanket Adamapure   \n",
       "65      Awesome HR Data Visualization & Prediction              Josh   \n",
       "61             Data Breaches Tableau Visualization            Xavier   \n",
       "165                               House Prices EDA    Dominik Gawlik   \n",
       "181                            Keras UNET with EDA      Chris Deotte   \n",
       "139    COVID_19_Image_Classification_Deep_AutoViML            RSESHA   \n",
       "203  public_krni_pdi_:( with two additional models            Andrij   \n",
       "\n",
       "             lastRunTime totalVotes  \n",
       "121  2018-11-29 13:42:16        458  \n",
       "109  2018-07-29 10:34:20         18  \n",
       "11   2019-08-27 15:55:56          4  \n",
       "2    2022-01-30 17:04:53          2  \n",
       "65   2021-04-27 13:20:41        147  \n",
       "61   2023-01-25 13:38:49        112  \n",
       "165  2017-02-20 10:51:47        606  \n",
       "181  2019-08-10 10:55:52        283  \n",
       "139  2021-08-08 22:46:10          6  \n",
       "203  2023-07-02 19:30:24        162  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_DF.sample(10)                        #Se muestran 10 resultados al azar de los notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZziTCBZaZCK"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 5 (1.75 puntos): Limpieza de metadatos de notebooks.</b>\n",
    "\n",
    "<b>Objetivo:</b> Limpiar los metadatos de notebooks de tal manera que no hayan elementos duplicados, ni hayan datos con valores inesperados.\n",
    "\n",
    "<b>Contexto:</b> Algunos notebooks también pueden repetirse como se ha explicado previamente.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- Recorrer la lista de resultados <i> notebooks </i> y dejar solo resultados únicos de notebooks.\n",
    "- Explorar los resultados obtenidos para verificar que los datos no contienen caracteres o elementos extraños.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar los 10 primeros notebooks únicos que han sido procesados.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "id": "EVuR-RaaaZCK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con valores nulos por columnas:\n",
      "ref             0\n",
      "title          13\n",
      "author         13\n",
      "lastRunTime    13\n",
      "totalVotes     13\n",
      "dtype: int64\n",
      "\n",
      "DataFrame con valores nulos por filas:\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "      ..\n",
      "226    0\n",
      "227    4\n",
      "228    0\n",
      "229    4\n",
      "230    4\n",
      "Length: 230, dtype: int64\n",
      "\n",
      "DataFrame solamente con las filas nulas:\n",
      "18     4\n",
      "19     4\n",
      "25     4\n",
      "125    4\n",
      "147    4\n",
      "164    4\n",
      "166    4\n",
      "176    4\n",
      "190    4\n",
      "201    4\n",
      "227    4\n",
      "229    4\n",
      "230    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################\n",
    "\n",
    "#Para la solucion se decide trabajar con los resultados obtenidos de los notebooks en formato DataFrame\n",
    "\n",
    "#a.) Eliminación de los resultados duplicados del Dataframe\n",
    "notebooks_DF_p=notebooks_DF.drop_duplicates()                    #Se utiliza drop_duplicates() para eliminar las filas duplicadas\n",
    "notebooks_DF_pp=notebooks_DF_p.drop([0],axis=0)                  #Se elimina la primera fila que corresponde con los nombres de las columnas.\n",
    "notebooks_DF_pp.index=range(1,len(notebooks_DF_pp)+1)            #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_inicial=len(notebooks_DF)                              #Se utiliza len para medir el tamaño del DataFrame sin procesar\n",
    "dimension_sin_duplicados=len(notebooks_DF_pp)                    #Se utiliza len para medir el tamaño del DataFrame preprocesado\n",
    "cantidad_duplicados=dimension_inicial-dimension_sin_duplicados   #Se calcula la cantidad de elementos duplicados\n",
    "\n",
    "#b.) Verificar si hay valores inesperados\n",
    "valores_null_columnas=notebooks_DF_pp.isnull().sum()             #Se guarda en un DataFrame el numero de valores nulos por columnas\n",
    "valores_null_filas=(notebooks_DF_pp.isnull().sum(axis=1))        #Se guarda en un DataFrame el numero de valores nulos por filas\n",
    "\n",
    "filas_nulas=[]                                                   #Lista vacia para almacenar las filas nulas                   \n",
    "for j in range(1,len(valores_null_filas)+1):                     #Ciclo repetitivo para recorrer el DataFrame con el numero de valores nulos por filas\n",
    "    if valores_null_filas[j]!=0:                                 #Cuando el valor de la fila es distinto de cero se añade en la lista \n",
    "        filas_nulas.append(j)\n",
    "valores_null_filas_filtradas=valores_null_filas[filas_nulas]     #Dataframe solamente con las filas nulas\n",
    "\n",
    "print(\"DataFrame con valores nulos por columnas:\")               #Se imprime el DataFrame con el numero de valores nulos por columnas\n",
    "print(valores_null_columnas)\n",
    "print(\"\\nDataFrame con valores nulos por filas:\")                #Se imprime el DataFrame con el numero de valores nulos por filas\n",
    "print(valores_null_filas)\n",
    "print(\"\\nDataFrame solamente con las filas nulas:\")              #Se imprimen el Dataframe anterior solamente con las filas nulas\n",
    "print(valores_null_filas_filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De  acuerdo al analisis anterior existen 13 filas con valores nulos. Las cuales tienen vacias todas sus columnas a excepcion de la primera\n",
    "#Se decide eliminar estas filas \n",
    "\n",
    "notebooks_DF_prep=notebooks_DF_pp.drop(filas_nulas,axis=0)       #Se eliminan las filas con valores nulos\n",
    "notebooks_DF_prep.index=range(1,len(notebooks_DF_prep)+1)        #Se modifica el indice del dataframe para que coincida con la nueva cantidad de filas\n",
    "dimension_final=len(notebooks_DF_prep)                           #Se utiliza len para medir el tamaño del DataFrame preprocesado final\n",
    "filas_eliminadas_vacias=len(filas_nulas)                         #Se utiliza len para medir el tamaño de filas eliminadas\n",
    "cantidad_filas_eliminadas=dimension_inicial-dimension_final      #Se calcula la cantidad de elementos eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension inicial del Dataframe: 251\n",
      "Dimension del Dataframe sin elementos duplicados: 230\n",
      "Cantidad de filas duplicadas: 21\n",
      "Dimension del DataFrame con datos únicos preprocesados: 217\n",
      "Cantidad de filas eliminadas vacias: 13\n",
      "Cantidad total de filas eliminadas: 34\n",
      "\n",
      "Dataframe con datos únicos preprocesados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aml0ali2000/linear-regression</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>1KB</td>\n",
       "      <td>2023-12-04 14:34:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasiviswanath00/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>378B</td>\n",
       "      <td>2022-05-25 12:08:15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drakedyban/mediumlinear-regression</td>\n",
       "      <td>Medium-Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2021-02-28 22:37:25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangitamule/linear-regressionproject</td>\n",
       "      <td>/Linear_Regression-Project</td>\n",
       "      <td>40KB</td>\n",
       "      <td>2022-02-03 06:41:39</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krishnamohanmaurya/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>5KB</td>\n",
       "      <td>2023-02-27 14:38:50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iflahgulzar/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2023-02-26 16:36:10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viveckrajasekar/linear-regression</td>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>13KB</td>\n",
       "      <td>2019-06-28 14:24:45</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pankajsinghardh/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>213B</td>\n",
       "      <td>2023-08-27 05:40:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nurmannaz/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>220B</td>\n",
       "      <td>2022-03-01 21:17:06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>epsitabose/linear-regression</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2022-02-09 11:47:13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ref                       title  size  \\\n",
       "1          aml0ali2000/linear-regression           Linear_regression   1KB   \n",
       "2      kasiviswanath00/linear-regression           linear_regression  378B   \n",
       "3     drakedyban/mediumlinear-regression    Medium-Linear_Regression   5KB   \n",
       "4   sangitamule/linear-regressionproject  /Linear_Regression-Project  40KB   \n",
       "5   krishnamohanmaurya/linear-regression           Linear_Regression   5KB   \n",
       "6          iflahgulzar/linear-regression           linear_regression   8KB   \n",
       "7      viveckrajasekar/linear-regression           Linear_Regression  13KB   \n",
       "8      pankajsinghardh/linear-regression           linear_regression  213B   \n",
       "9            nurmannaz/linear-regression           linear_regression  220B   \n",
       "10          epsitabose/linear-regression           linear_regression   2MB   \n",
       "\n",
       "            lastUpdated downloadCount voteCount usabilityRating  \n",
       "1   2023-12-04 14:34:14             7         2       0.3529412  \n",
       "2   2022-05-25 12:08:15            15         2       0.1764706  \n",
       "3   2021-02-28 22:37:25            19         1          0.4375  \n",
       "4   2022-02-03 06:41:39            14         2      0.29411766  \n",
       "5   2023-02-27 14:38:50             7         2       0.1764706  \n",
       "6   2023-02-26 16:36:10             9         1       0.1764706  \n",
       "7   2019-06-28 14:24:45            61         1      0.11764706  \n",
       "8   2023-08-27 05:40:10             6         0          0.3125  \n",
       "9   2022-03-01 21:17:06            14         0       0.1764706  \n",
       "10  2022-02-09 11:47:13             6         1             0.0  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c.) Impresion de resultados\n",
    "print(\"Dimension inicial del Dataframe:\",dimension_inicial)      #Se imprime el tamaño del DataFrame sin procesar\n",
    "print(\"Dimension del Dataframe sin elementos duplicados:\",dimension_sin_duplicados) #Se imprime el tamaño del DataFrame preprocesado\n",
    "print(\"Cantidad de filas duplicadas:\",cantidad_duplicados)       #Se imprime la cantidad de elementos duplicados\n",
    "print(\"Dimension del DataFrame con datos únicos preprocesados:\",dimension_final)    #Se imprime la cantidad de elementos del DataFrame preprocesado final\n",
    "print(\"Cantidad de filas eliminadas vacias:\",filas_eliminadas_vacias)   #Se imprime la cantidad de filas_eliminadas que estaban vacías\n",
    "print(\"Cantidad total de filas eliminadas:\",cantidad_filas_eliminadas)  #Se imprime la cantidad de filas_eliminadas\n",
    "print(\"\\nDataframe con datos únicos preprocesados:\")                           \n",
    "datasets_DF_prep[:10]                                            #Se imprimen los 10 primeros resultados del DataFrame preprocesado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>kralmachine/data-visualization-of-suicide-rates</td>\n",
       "      <td>Data Visualization of Suicide Rates</td>\n",
       "      <td>KraLMachine</td>\n",
       "      <td>2019-06-30 19:20:25</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>therealcyberlord/coronavirus-covid-19-visualiz...</td>\n",
       "      <td>Coronavirus (COVID-19) Visualization &amp; Prediction</td>\n",
       "      <td>Xingyu Bian</td>\n",
       "      <td>2023-01-17 00:44:38</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>miklgr500/ghost-drift-and-outliers</td>\n",
       "      <td>\"\"\"Ghost\"\" drift and Outliers\"</td>\n",
       "      <td>Welf Crozzo</td>\n",
       "      <td>2020-04-12 06:25:26</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sgantayat9/covid-19-bcell-classification-86-ac...</td>\n",
       "      <td>Covid_19_BCell_Classification_86%_Accuracy</td>\n",
       "      <td>Shubham Gantayat</td>\n",
       "      <td>2020-09-15 06:37:04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pavansanagapati/pandas-bokeh-visualization-tut...</td>\n",
       "      <td>Pandas Bokeh  Visualization Tutorial</td>\n",
       "      <td>Pavan Sanagapati</td>\n",
       "      <td>2020-07-05 01:20:21</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>larsupb/covid-19-forecast-germany-with-lgbm-an...</td>\n",
       "      <td>covid-19 forecast Germany with lgbm and keras</td>\n",
       "      <td>Lars Hackstein</td>\n",
       "      <td>2020-03-19 09:42:13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>shivamb/0-cpe-getting-familier-with-problem-an...</td>\n",
       "      <td>0. CPE - Getting Familier with Problem and Dat...</td>\n",
       "      <td>Shivam Bansal</td>\n",
       "      <td>2018-12-04 15:20:50</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>rajatraj0502/most-streamed-spotify-songs-2023</td>\n",
       "      <td>Most Streamed Spotify Songs 2023</td>\n",
       "      <td>Rajat Raj</td>\n",
       "      <td>2023-08-27 19:23:46</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>evanmiller/pipelines-gridsearch-awesome-ml-pip...</td>\n",
       "      <td>Pipelines + GridSearch  = Awesome ML pipelines</td>\n",
       "      <td>Evan Miller</td>\n",
       "      <td>2017-10-06 22:35:26</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>subinium/kaggle-2020-visualization-analysis</td>\n",
       "      <td>[Kaggle 2020] Visualization &amp; Analysis</td>\n",
       "      <td>Subin An</td>\n",
       "      <td>2021-03-26 07:34:46</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ref  \\\n",
       "42     kralmachine/data-visualization-of-suicide-rates   \n",
       "18   therealcyberlord/coronavirus-covid-19-visualiz...   \n",
       "216                 miklgr500/ghost-drift-and-outliers   \n",
       "132  sgantayat9/covid-19-bcell-classification-86-ac...   \n",
       "50   pavansanagapati/pandas-bokeh-visualization-tut...   \n",
       "135  larsupb/covid-19-forecast-germany-with-lgbm-an...   \n",
       "96   shivamb/0-cpe-getting-familier-with-problem-an...   \n",
       "194      rajatraj0502/most-streamed-spotify-songs-2023   \n",
       "201  evanmiller/pipelines-gridsearch-awesome-ml-pip...   \n",
       "24         subinium/kaggle-2020-visualization-analysis   \n",
       "\n",
       "                                                 title            author  \\\n",
       "42                 Data Visualization of Suicide Rates       KraLMachine   \n",
       "18   Coronavirus (COVID-19) Visualization & Prediction       Xingyu Bian   \n",
       "216                     \"\"\"Ghost\"\" drift and Outliers\"       Welf Crozzo   \n",
       "132         Covid_19_BCell_Classification_86%_Accuracy  Shubham Gantayat   \n",
       "50                Pandas Bokeh  Visualization Tutorial  Pavan Sanagapati   \n",
       "135      covid-19 forecast Germany with lgbm and keras    Lars Hackstein   \n",
       "96   0. CPE - Getting Familier with Problem and Dat...     Shivam Bansal   \n",
       "194                   Most Streamed Spotify Songs 2023         Rajat Raj   \n",
       "201     Pipelines + GridSearch  = Awesome ML pipelines       Evan Miller   \n",
       "24              [Kaggle 2020] Visualization & Analysis          Subin An   \n",
       "\n",
       "             lastRunTime totalVotes  \n",
       "42   2019-06-30 19:20:25        165  \n",
       "18   2023-01-17 00:44:38       2228  \n",
       "216  2020-04-12 06:25:26         64  \n",
       "132  2020-09-15 06:37:04          5  \n",
       "50   2020-07-05 01:20:21        144  \n",
       "135  2020-03-19 09:42:13         17  \n",
       "96   2018-12-04 15:20:50        131  \n",
       "194  2023-08-27 19:23:46         38  \n",
       "201  2017-10-06 22:35:26         48  \n",
       "24   2021-03-26 07:34:46        361  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_DF_prep.sample(10)                                      #Se muestran 10 resultados al azar del DataFrame preprocesado final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xmoduncaZCL"
   },
   "source": [
    "### Paso 2.2: Integración de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6F8KNJuaZCL"
   },
   "source": [
    "<div style=\"background-color: #FFFF99; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Ejercicio 6 (2 ptos): Integración de datos obtenidos (tanto de datasets y notebooks) </b>\n",
    "\n",
    "<b>Objetivo:</b> Crear un dataframe único donde consten los datos de los datasets como de los notebooks.\n",
    "\n",
    "<b>Requisitos:</b>\n",
    "\n",
    "- A partir de la estructuras de datos <i> datasets </i> y <i> notebooks </i>, determinar cuáles los atributos comunes y cuáles son diferentes para crear una sola estructura tipo dataframe que almacene todos los datos extraídos.\n",
    "\n",
    "<b>Salida esperada:</b> Presentar un <i>sample</i> de 10 elementos que consten en el dataframe único\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwgU4fEkaZCM"
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# SOLUCIÓN\n",
    "######################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "finalized": {
   "timestamp": 1621297898005,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
